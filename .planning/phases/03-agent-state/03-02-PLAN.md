---
phase: 03-agent-state
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - lib/agent_com/socket.ex
  - lib/agent_com/endpoint.ex
  - lib/agent_com/task_queue.ex
  - lib/agent_com/presence.ex
autonomous: true

must_haves:
  truths:
    - "Agent connecting via WebSocket starts an AgentFSM process; disconnecting stops it and reclaims any assigned task"
    - "Socket forwards task_accepted/task_complete/task_failed events to AgentFSM, keeping FSM state synchronized"
    - "GET /api/agents returns fsm_state field for each connected agent"
    - "GET /api/agents/:agent_id/state returns detailed FSM state including current_task_id, flags, capabilities"
    - "TaskQueue.reclaim_task/1 resets an assigned task to queued with generation bump"
    - "Reconnecting agent terminates old FSM before creating new one (Pitfall 5)"
  artifacts:
    - path: "lib/agent_com/socket.ex"
      provides: "AgentFSM lifecycle management in do_identify and terminate; task event forwarding"
      contains: "AgentSupervisor.start_agent"
    - path: "lib/agent_com/endpoint.ex"
      provides: "HTTP endpoints for agent FSM state queries"
      contains: "api/agents/:agent_id/state"
    - path: "lib/agent_com/task_queue.ex"
      provides: "reclaim_task/1 public API for AgentFSM disconnect/timeout reclamation"
      contains: "def reclaim_task"
    - path: "lib/agent_com/presence.ex"
      provides: "update_fsm_state/2 for AgentFSM to push state changes to Presence cache"
      contains: "def update_fsm_state"
  key_links:
    - from: "lib/agent_com/socket.ex"
      to: "lib/agent_com/agent_fsm.ex"
      via: "AgentFSM.task_accepted/task_completed/task_failed casts from Socket handlers"
      pattern: "AgentFSM\\.task_(accepted|completed|failed)"
    - from: "lib/agent_com/socket.ex"
      to: "lib/agent_com/agent_supervisor.ex"
      via: "start_agent in do_identify, stop_agent for reconnect"
      pattern: "AgentSupervisor\\.(start_agent|stop_agent)"
    - from: "lib/agent_com/agent_fsm.ex"
      to: "lib/agent_com/task_queue.ex"
      via: "reclaim_task call on disconnect/timeout"
      pattern: "TaskQueue\\.reclaim_task"
    - from: "lib/agent_com/endpoint.ex"
      to: "lib/agent_com/agent_fsm.ex"
      via: "AgentFSM.get_state and list_all for HTTP responses"
      pattern: "AgentFSM\\.(get_state|list_all)"
---

<objective>
Wire the AgentFSM infrastructure from Plan 01 into the existing Socket, Endpoint, TaskQueue, and Presence modules. Socket starts/stops FSM processes on connect/disconnect and forwards task lifecycle events. Endpoint exposes FSM state via HTTP API. TaskQueue gains a reclaim_task function for disconnect/timeout reclamation. Presence gains an fsm_state field updated by AgentFSM on transitions.

Purpose: Complete the integration so agent state is visible, synchronized, and actionable across all hub interfaces.
Output: Modified socket.ex, endpoint.ex, task_queue.ex, presence.ex; updated agent_fsm.ex with Presence push
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-agent-state/03-RESEARCH.md
@.planning/phases/03-agent-state/03-01-SUMMARY.md
@lib/agent_com/socket.ex
@lib/agent_com/endpoint.ex
@lib/agent_com/task_queue.ex
@lib/agent_com/presence.ex
@lib/agent_com/agent_fsm.ex
@lib/agent_com/agent_supervisor.ex
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire Socket to AgentFSM lifecycle and add reclaim_task to TaskQueue</name>
  <files>lib/agent_com/socket.ex, lib/agent_com/task_queue.ex, lib/agent_com/agent_fsm.ex</files>
  <action>
**Socket.do_identify changes:**

In `do_identify/3`, BEFORE the existing `Registry.register` call, add reconnect handling and FSM startup:

```elixir
# Handle reconnect: stop old FSM if one exists (Pitfall 5)
case Registry.lookup(AgentCom.AgentFSMRegistry, agent_id) do
  [{old_pid, _}] ->
    AgentCom.AgentSupervisor.stop_agent(old_pid)
  [] -> :ok
end

# Start new AgentFSM
{:ok, _fsm_pid} = AgentCom.AgentSupervisor.start_agent([
  agent_id: agent_id,
  ws_pid: self(),
  name: name,
  capabilities: capabilities
])
```

The FSM start must happen BEFORE Registry.register and Presence.register so the FSM is ready when other modules query it. Keep all existing logic (Registry, Presence, PubSub subscriptions, Analytics) after the FSM start.

**Socket task handler changes:**

In `handle_msg` for `"task_accepted"` (around line 297): After the existing `AgentCom.TaskQueue.update_progress(task_id)` call, add:
```elixir
AgentCom.AgentFSM.task_accepted(state.agent_id, task_id)
```

In `handle_msg` for `"task_complete"` (around line 312): After the `{:ok, _task}` branch of the TaskQueue.complete_task call, add:
```elixir
AgentCom.AgentFSM.task_completed(state.agent_id)
```

In `handle_msg` for `"task_failed"` (around line 330): After the `{:ok, :retried, _task}` and `{:ok, :dead_letter, _task}` branches, add:
```elixir
AgentCom.AgentFSM.task_failed(state.agent_id)
```

In `handle_info` for `{:push_task, task}` (around line 156): After pushing the task_assign message, add:
```elixir
# Notify FSM about task assignment
task_id = task["task_id"] || task[:task_id]
if task_id, do: AgentCom.AgentFSM.assign_task(state.agent_id, task_id)
```

**Socket.terminate changes:**

The existing terminate already calls Registry.unregister and Presence.unregister. Do NOT add FSM cleanup here -- the AgentFSM's Process.monitor :DOWN handler owns task reclamation (per research Pitfall 3 -- clear ownership). The FSM will self-terminate when it receives the :DOWN message. Socket.terminate only handles Registry (WebSocket pid) and Analytics.

**TaskQueue.reclaim_task/1:**

Add a new public API function to TaskQueue:

```elixir
@doc """
Reclaim a specific task from an agent. Used by AgentFSM on disconnect or
acceptance timeout. Resets task to :queued, bumps generation, re-adds to
priority index. Returns {:ok, task} or {:error, :not_found | :not_assigned}.
Idempotent: if task is already queued/completed, returns {:error, :not_assigned}.
"""
def reclaim_task(task_id) do
  GenServer.call(__MODULE__, {:reclaim_task, task_id})
end
```

Add the handle_call clause for `{:reclaim_task, task_id}` in the GenServer:
1. Look up task in main DETS table using the existing `lookup_task` pattern (`:dets.lookup(@tasks_table, task_id)`)
2. If found and status is `:assigned`:
   - Create reclaimed task: set status to `:queued`, clear `assigned_to` and `assigned_at`, bump `generation` by 1, update `updated_at`
   - Add history entry: `{:reclaimed, now, "agent_disconnect"}`
   - Cap history at @history_cap
   - Persist to DETS with sync (using existing persist_task pattern)
   - Add back to priority index (using existing add_to_priority_index pattern)
   - Broadcast event via PubSub: `Phoenix.PubSub.broadcast(AgentCom.PubSub, "tasks", {:task_event, %{event: "task_reclaimed", task_id: task_id, ...}})`
   - Reply `{:ok, reclaimed_task}`
3. If found but not `:assigned`: reply `{:error, :not_assigned}`
4. If not found: reply `{:error, :not_found}`

**AgentFSM update -- replace stub reclaim with real call:**

Update `AgentFSM` to call `AgentCom.TaskQueue.reclaim_task/1` instead of any stub approach from Plan 01. In the :DOWN handler and acceptance_timeout handler, ensure the call is:
```elixir
case AgentCom.TaskQueue.reclaim_task(state.current_task_id) do
  {:ok, _task} -> Logger.info("AgentFSM: reclaimed task #{state.current_task_id} from #{state.agent_id}")
  {:error, reason} -> Logger.warning("AgentFSM: reclaim failed for #{state.current_task_id}: #{reason}")
end
```

This is idempotent -- if Socket's TaskQueue.complete_task already ran (task not :assigned), reclaim returns {:error, :not_assigned} and no harm done (Pitfall 3).
  </action>
  <verify>
Run `mix compile` -- zero errors, zero warnings. Verify Socket.do_identify includes AgentSupervisor.start_agent call. Verify TaskQueue has reclaim_task/1 in public API and handle_call. Verify Socket task handlers call AgentFSM notification functions.
  </verify>
  <done>Socket starts FSM on connect, handles reconnect by stopping old FSM, forwards all task events to AgentFSM. TaskQueue.reclaim_task/1 exists and is idempotent. AgentFSM uses real reclaim_task on disconnect/timeout.</done>
</task>

<task type="auto">
  <name>Task 2: Add HTTP agent state endpoints and wire AgentFSM to Presence</name>
  <files>lib/agent_com/endpoint.ex, lib/agent_com/presence.ex, lib/agent_com/agent_fsm.ex</files>
  <action>
**Presence.update_fsm_state/2:**

Add a new function to Presence that AgentFSM calls on state transitions:

```elixir
@doc "Update an agent's FSM state. Called by AgentFSM on state transitions."
def update_fsm_state(agent_id, fsm_state) do
  GenServer.cast(__MODULE__, {:update_fsm_state, agent_id, fsm_state})
end
```

Add handle_cast:
```elixir
def handle_cast({:update_fsm_state, agent_id, fsm_state}, state) do
  case Map.get(state, agent_id) do
    nil -> {:noreply, state}
    entry ->
      updated = Map.put(entry, :fsm_state, fsm_state)
      {:noreply, Map.put(state, agent_id, updated)}
  end
end
```

This does NOT broadcast to PubSub "presence" topic -- FSM state changes are frequent and internal. The existing `:status_changed` broadcast remains for human-visible status updates. FSM state is queryable via the existing Presence.get/list and the new HTTP endpoints.

**AgentFSM Presence push:**

Update the private `transition/2` function in AgentFSM to call `AgentCom.Presence.update_fsm_state(state.agent_id, new_state)` after a successful transition. Also call it in init after determining initial state (idle or assigned).

In the :DOWN handler (disconnect), call `AgentCom.Presence.update_fsm_state(state.agent_id, :offline)` before stopping.

**Endpoint changes -- enhance existing /api/agents:**

The existing `get "/api/agents"` route returns Presence data. Update the map function to include the new `fsm_state` field:

In the existing Enum.map block for /api/agents, add:
```elixir
"fsm_state" => Map.get(a, :fsm_state, "unknown"),
```

This is backward-compatible: agents connected before Phase 3 (if any) will show "unknown".

**Endpoint changes -- new /api/agents/:agent_id/state route:**

Add a new route BEFORE the existing `/api/agents/:agent_id/subscriptions` route (route ordering matters in Plug.Router):

```elixir
get "/api/agents/:agent_id/state" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    case AgentCom.AgentFSM.get_state(agent_id) do
      {:ok, agent_state} ->
        send_json(conn, 200, %{
          "agent_id" => agent_state.agent_id,
          "fsm_state" => to_string(agent_state.fsm_state),
          "current_task_id" => agent_state.current_task_id,
          "capabilities" => Enum.map(agent_state.capabilities, fn cap ->
            if is_map(cap) do
              Map.new(cap, fn {k, v} -> {to_string(k), v} end)
            else
              cap
            end
          end),
          "flags" => Enum.map(agent_state.flags, &to_string/1),
          "connected_at" => agent_state.connected_at,
          "last_state_change" => agent_state.last_state_change,
          "name" => agent_state.name
        })
      {:error, :not_found} ->
        send_json(conn, 404, %{"error" => "agent_not_found"})
    end
  end
end
```

**Endpoint changes -- new /api/agents/states route:**

Add a new route for listing all agent FSM states. Place it BEFORE any parameterized `/api/agents/:agent_id` routes (same ordering principle as tasks):

```elixir
get "/api/agents/states" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    agents = AgentCom.AgentFSM.list_all()
    formatted = Enum.map(agents, fn a ->
      %{
        "agent_id" => a.agent_id,
        "fsm_state" => to_string(a.fsm_state),
        "current_task_id" => a.current_task_id,
        "capabilities" => Enum.map(a.capabilities || [], fn cap ->
          if is_map(cap) do
            Map.new(cap, fn {k, v} -> {to_string(k), v} end)
          else
            cap
          end
        end),
        "flags" => Enum.map(a.flags || [], &to_string/1),
        "connected_at" => a.connected_at,
        "name" => a.name
      }
    end)
    send_json(conn, 200, %{"agents" => formatted})
  end
end
```

**Endpoint moduledoc update:**

Add these routes to the moduledoc comment:
```
- GET    /api/agents/states          -- All agent FSM states (auth required)
- GET    /api/agents/:id/state       -- Single agent FSM state detail (auth required)
```

**Route ordering in endpoint.ex:** The order must be:
1. `/api/agents/states` (specific path)
2. `/api/agents/:agent_id/state` (parameterized)
3. `/api/agents/:agent_id/subscriptions` (existing parameterized)

Place both new routes BEFORE the existing `/api/agents/:agent_id/subscriptions` route.
  </action>
  <verify>
Run `mix compile` -- zero errors, zero warnings. Verify Presence module has update_fsm_state/2 function. Verify endpoint has /api/agents/states and /api/agents/:agent_id/state routes. Verify /api/agents response includes fsm_state field. Verify AgentFSM transition function calls Presence.update_fsm_state.
  </verify>
  <done>HTTP API exposes agent FSM state via existing /api/agents (with fsm_state field) and new /api/agents/:id/state (detailed view) and /api/agents/states (all FSMs). Presence module stores fsm_state updated by AgentFSM on each transition. All compiles cleanly.</done>
</task>

</tasks>

<verification>
After both tasks:
1. `mix compile` produces zero errors and zero warnings
2. Socket.do_identify starts AgentFSM on connect, handles reconnect
3. Socket.terminate does NOT duplicate FSM cleanup (FSM owns task reclamation)
4. Socket task handlers notify AgentFSM of task_accepted/task_complete/task_failed
5. TaskQueue.reclaim_task/1 exists, is idempotent, bumps generation
6. GET /api/agents includes fsm_state for each agent
7. GET /api/agents/:id/state returns detailed FSM state or 404
8. GET /api/agents/states returns all FSM states
9. Presence stores fsm_state updated by AgentFSM
</verification>

<success_criteria>
- Agent WebSocket connect creates an AgentFSM; disconnect triggers :DOWN which reclaims tasks and terminates FSM
- Reconnecting agent stops old FSM before starting new one
- Socket task events keep AgentFSM synchronized (assigned -> working -> idle)
- TaskQueue.reclaim_task is idempotent and safe to call from both timeout and disconnect paths
- All agent state queryable via HTTP API (fsm_state, capabilities, flags, current_task)
- Presence has fsm_state field for each connected agent
- All modules compile without warnings
</success_criteria>

<output>
After completion, create `.planning/phases/03-agent-state/03-02-SUMMARY.md`
</output>
