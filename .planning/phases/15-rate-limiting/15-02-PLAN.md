---
phase: 15-rate-limiting
plan: 02
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - lib/agent_com/socket.ex
  - lib/agent_com/plugs/rate_limit.ex
  - lib/agent_com/endpoint.ex
  - lib/agent_com/scheduler.ex
autonomous: true

must_haves:
  truths:
    - "A WS message from an identified agent that exceeds its bucket gets a rate_limited error frame with retry_after_ms"
    - "A WS message approaching 80% usage triggers a rate_limit_warning frame before the message is processed normally"
    - "An HTTP request that exceeds its bucket receives 429 with Retry-After header and JSON error body"
    - "Rate-limited agents are excluded from Scheduler assignment pool -- no new tasks assigned"
    - "The identify message is NOT rate limited (agent_id unknown before identification)"
    - "Unidentified connections skip rate limiting entirely"
    - "Different tiers are enforced independently -- exhausting light does not block normal messages"
  artifacts:
    - path: "lib/agent_com/socket.ex"
      provides: "Rate limit check between validation and handle_msg"
      contains: "RateLimiter.check"
    - path: "lib/agent_com/plugs/rate_limit.ex"
      provides: "HTTP rate limit plug returning 429 with Retry-After"
      contains: "defmodule AgentCom.Plugs.RateLimit"
    - path: "lib/agent_com/endpoint.ex"
      provides: "RateLimit plug wired into authenticated HTTP routes"
      contains: "Plugs.RateLimit"
    - path: "lib/agent_com/scheduler.ex"
      provides: "Rate-limited agent exclusion in try_schedule_all"
      contains: "RateLimiter.rate_limited?"
  key_links:
    - from: "lib/agent_com/socket.ex"
      to: "lib/agent_com/rate_limiter.ex"
      via: "RateLimiter.check in handle_in after validation"
      pattern: "RateLimiter\\.check"
    - from: "lib/agent_com/plugs/rate_limit.ex"
      to: "lib/agent_com/rate_limiter.ex"
      via: "RateLimiter.check in plug call/2"
      pattern: "RateLimiter\\.check"
    - from: "lib/agent_com/scheduler.ex"
      to: "lib/agent_com/rate_limiter.ex"
      via: "RateLimiter.rate_limited? filter in try_schedule_all"
      pattern: "RateLimiter\\.rate_limited\\?"
---

<objective>
Wire rate limiting into all three entry points: WebSocket messages, HTTP requests, and Scheduler assignment.

Purpose: This is the integration plan that makes rate limiting actually enforce limits. Without this, the RateLimiter module exists but nothing calls it. After this plan, misbehaving agents are throttled on WS, receive 429 on HTTP, and stop getting new task assignments.
Output: Modified Socket, new RateLimit plug, modified Endpoint, modified Scheduler.
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-rate-limiting/15-RESEARCH.md
@.planning/phases/15-rate-limiting/15-CONTEXT.md
@.planning/phases/15-rate-limiting/15-01-SUMMARY.md
@lib/agent_com/socket.ex
@lib/agent_com/endpoint.ex
@lib/agent_com/scheduler.ex
@lib/agent_com/plugs/require_auth.ex (pattern for the new plug)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate rate limiting into Socket.handle_in and Scheduler</name>
  <files>
    lib/agent_com/socket.ex
    lib/agent_com/scheduler.ex
  </files>
  <action>
**Modify `lib/agent_com/socket.ex`:**

Add `alias AgentCom.RateLimiter` to the existing alias block at the top of the module.

In `handle_in/2`, after the `Validation.validate_ws_message(msg)` succeeds with `{:ok, validated}`, insert a rate limit check BEFORE calling `handle_msg(validated, state)`. The flow becomes:

```
Jason.decode -> Validation.validate_ws_message -> check_rate_limit -> handle_msg
```

Add a private function `check_rate_limit/2` that:
1. If `state.identified` is false, skip rate limiting (return and proceed to handle_msg -- the identify message is the only valid unidentified message, and rate limiting needs agent_id)
2. Get `message_type` from `Map.get(validated, "type")`
3. Get tier from `RateLimiter.Config.ws_tier(message_type)`
4. Call `RateLimiter.check(state.agent_id, :ws, tier)`
5. On `{:allow, _}` -- proceed to `handle_msg(validated, state)` normally
6. On `{:allow, :exempt}` -- proceed to `handle_msg(validated, state)` normally
7. On `{:warn, remaining}` -- send a warning frame FIRST, then proceed to `handle_msg`. The warning frame is a JSON push:
   ```json
   {"type": "rate_limit_warning", "tier": "normal", "remaining": 12, "capacity": 60}
   ```
   Use `RateLimiter.capacity(state.agent_id, :ws, tier)` for the capacity value.
   Since WebSock `handle_in` can only return one push or a list of frames, handle this by:
   - Return `{:push, [{:text, warn_json}, {:text, handle_msg_result}], state}` -- BUT this requires restructuring handle_msg to return the frame data instead of the full tuple.
   - **Simpler approach:** Send the warning via `Process.send(self(), {:send_rate_warning, warn_frame}, [])` and handle it in `handle_info`, OR just return the warning frame and let the message be processed on the next incoming frame (not ideal).
   - **Best approach for this codebase:** The warn path should process the message normally AND prepend a warning frame. Refactor the check so that:
     - Extract the rate limit check result
     - If `:warn`, compute warning frame, call handle_msg to get its result, then combine frames
     - If the handle_msg result is `{:push, {:text, reply}, state}`, return `{:push, [{:text, warn_json}, {:text, reply}], state}`
     - If the handle_msg result is `{:ok, state}`, return `{:push, {:text, warn_json}, state}`
8. On `{:deny, retry_after_ms}` -- call `RateLimiter.record_violation(state.agent_id)` to track progressive backoff, then push a structured error frame and do NOT call handle_msg:
   ```json
   {"type": "rate_limited", "retry_after_ms": 2000, "tier": "normal"}
   ```
   Return `{:push, {:text, deny_json}, state}`

The modified `handle_in/2` structure:
```elixir
def handle_in({text, [opcode: :text]}, state) do
  request_id = Base.encode16(:crypto.strong_rand_bytes(8), case: :lower)
  Logger.metadata(request_id: request_id)

  case Jason.decode(text) do
    {:ok, msg} ->
      case Validation.validate_ws_message(msg) do
        {:ok, validated} ->
          rate_limit_and_handle(validated, state)
        {:error, errors} ->
          handle_validation_failure(msg, errors, state)
      end
    {:error, _} ->
      reply_error("invalid_json", state)
  end
end

defp rate_limit_and_handle(msg, %{identified: false} = state) do
  # Before identification, skip rate limiting (identify is the only valid message)
  handle_msg(msg, state)
end

defp rate_limit_and_handle(msg, state) do
  message_type = Map.get(msg, "type")
  tier = RateLimiter.Config.ws_tier(message_type)

  case RateLimiter.check(state.agent_id, :ws, tier) do
    {:allow, _} ->
      handle_msg(msg, state)

    {:allow, :exempt} ->
      handle_msg(msg, state)

    {:warn, remaining} ->
      capacity = RateLimiter.capacity(state.agent_id, :ws, tier)
      warn_frame = Jason.encode!(%{
        "type" => "rate_limit_warning",
        "tier" => to_string(tier),
        "remaining" => remaining,
        "capacity" => capacity
      })
      # Process message normally, prepend warning frame
      case handle_msg(msg, state) do
        {:push, {:text, reply}, new_state} ->
          {:push, [{:text, warn_frame}, {:text, reply}], new_state}
        {:push, frames, new_state} when is_list(frames) ->
          {:push, [{:text, warn_frame} | frames], new_state}
        {:ok, new_state} ->
          {:push, {:text, warn_frame}, new_state}
        other ->
          other
      end

    {:deny, retry_after_ms} ->
      RateLimiter.record_violation(state.agent_id)
      deny_frame = Jason.encode!(%{
        "type" => "rate_limited",
        "retry_after_ms" => retry_after_ms,
        "tier" => to_string(tier)
      })
      {:push, {:text, deny_frame}, state}
  end
end
```

**Modify `lib/agent_com/scheduler.ex`:**

In the `try_schedule_all/1` function, add a filter to exclude rate-limited agents. After the existing `Enum.filter(fn a -> a.fsm_state == :idle end)`, add:

```elixir
|> Enum.reject(fn a -> AgentCom.RateLimiter.rate_limited?(a.agent_id) end)
```

This goes after the `:idle` filter but before the `case idle_agents` block. Rate-limited agents keep their existing tasks (no disruption) but don't get new assignments until their violation state clears.

Commit: `feat(15-02): integrate rate limiting into WebSocket handler and Scheduler`
  </action>
  <verify>`mix compile --warnings-as-errors` succeeds. Existing tests pass: `mix test --exclude smoke`</verify>
  <done>Socket.handle_in gates all identified-agent messages through RateLimiter.check before handle_msg. Denied messages get rate_limited error frame. Warning messages get rate_limit_warning prepended. Scheduler excludes rate-limited agents from assignment pool.</done>
</task>

<task type="auto">
  <name>Task 2: Create HTTP RateLimit plug and wire into Endpoint</name>
  <files>
    lib/agent_com/plugs/rate_limit.ex
    lib/agent_com/endpoint.ex
  </files>
  <action>
**Create `lib/agent_com/plugs/rate_limit.ex`:**

Follow the pattern of `AgentCom.Plugs.RequireAuth`. The plug:

```elixir
defmodule AgentCom.Plugs.RateLimit do
  @moduledoc """
  HTTP rate limiting plug. Returns 429 Too Many Requests when rate limit exceeded.

  Uses agent_id from conn.assigns[:authenticated_agent] (set by RequireAuth plug)
  or falls back to IP address for unauthenticated endpoints.

  ## Usage

      # In endpoint route:
      conn = AgentCom.Plugs.RateLimit.call(conn, action: :post_task)
  """
  import Plug.Conn

  def init(opts), do: opts

  def call(conn, opts) do
    action = Keyword.get(opts, :action, :unknown)
    tier = AgentCom.RateLimiter.Config.http_tier(action)

    # Use authenticated agent_id if available, fall back to IP
    agent_id = conn.assigns[:authenticated_agent] || format_ip(conn.remote_ip)

    case AgentCom.RateLimiter.check(agent_id, :http, tier) do
      {:allow, _} -> conn
      {:allow, :exempt} -> conn
      {:warn, _} -> conn  # HTTP has no warning channel, just allow

      {:deny, retry_after_ms} ->
        AgentCom.RateLimiter.record_violation(agent_id)
        retry_seconds = max(div(retry_after_ms, 1000), 1)

        conn
        |> put_resp_header("retry-after", Integer.to_string(retry_seconds))
        |> put_resp_content_type("application/json")
        |> send_resp(429, Jason.encode!(%{
          "error" => "rate_limited",
          "retry_after_ms" => retry_after_ms,
          "tier" => to_string(tier)
        }))
        |> halt()
    end
  end

  defp format_ip({a, b, c, d}), do: "ip:#{a}.#{b}.#{c}.#{d}"
  defp format_ip(ip), do: "ip:#{inspect(ip)}"
end
```

**Modify `lib/agent_com/endpoint.ex`:**

Wire the RateLimit plug into HTTP routes. The pattern is: after RequireAuth (if present), before business logic. For unauthenticated endpoints, call RateLimit directly with IP-based identification.

For each route that uses RequireAuth, add a RateLimit call immediately after. The action atom should match the HTTP tier classification in Config.

**Authenticated routes -- add RateLimit after RequireAuth:**

For routes that already call `AgentCom.Plugs.RequireAuth.call(conn, [])`, add `AgentCom.Plugs.RateLimit.call(conn, action: :action_name)` on the next line, inside the `if !conn.halted` block. The pattern:

```elixir
post "/api/message" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    conn = AgentCom.Plugs.RateLimit.call(conn, action: :post_message)
    if conn.halted do
      conn
    else
      # ... existing business logic
    end
  end
end
```

Apply this pattern to these authenticated routes with their action names:
- `POST /api/message` -> `:post_message`
- `POST /api/channels` -> `:post_channel`
- `POST /api/channels/:ch/subscribe` -> `:post_channel_subscribe`
- `POST /api/channels/:ch/unsubscribe` -> `:post_channel_unsubscribe`
- `POST /api/channels/:ch/publish` -> `:post_channel_publish`
- `POST /api/admin/push-task` -> `:post_admin_push_task`
- `POST /api/tasks` -> `:post_task`
- `GET /api/tasks` -> `:get_tasks`
- `GET /api/tasks/:task_id` -> `:get_task_detail`
- `POST /api/tasks/:task_id/retry` -> `:post_task_retry`

**Unauthenticated routes -- add RateLimit with IP-based identification:**

For routes with no auth that should still be rate limited (to prevent abuse):
- `POST /api/onboard/register` -> `:post_onboard_register` (heavy tier -- prevent registration spam)
- `GET /api/agents` -> `:get_agents` (light tier)
- `GET /api/channels` -> `:get_channels` (light tier)
- `GET /api/channels/:channel` -> `:get_channel_info` (light tier)
- `GET /api/metrics` -> `:get_metrics` (light tier)

For these, add `conn = AgentCom.Plugs.RateLimit.call(conn, action: :action_name)` at the top of the route, before any business logic. Since there's no RequireAuth, the plug will use IP-based identification.

**Do NOT rate limit these endpoints** (dashboard-critical or health):
- `GET /health` -- must always respond for uptime monitoring
- `GET /api/dashboard/state` -- dashboard polling, already local-only
- `GET /api/schemas` -- schema discovery, low volume
- `GET /dashboard` -- HTML page, single load
- `GET /ws` and `GET /ws/dashboard` -- WebSocket upgrades (WS has its own rate limiting)
- `GET /sw.js`, vapid-key, push-subscribe -- dashboard infrastructure

Commit: `feat(15-02): add HTTP RateLimit plug and wire into Endpoint routes`
  </action>
  <verify>`mix compile --warnings-as-errors` succeeds. `mix test --exclude smoke` passes. Verify the plug file exists and endpoint references it.</verify>
  <done>RateLimit plug exists and returns 429 with Retry-After header when rate limited. All significant HTTP routes are wired through the plug. Unauthenticated routes use IP-based rate limiting. Health and dashboard endpoints are exempt.</done>
</task>

</tasks>

<verification>
1. `mix compile --warnings-as-errors` -- no warnings
2. `mix test --exclude smoke` -- all existing tests pass (no regressions)
3. Rate limit check is called in Socket.handle_in between validation and handle_msg
4. Scheduler filters out rate-limited agents before assignment
5. HTTP routes return 429 when rate limit exceeded
</verification>

<success_criteria>
- WebSocket messages from identified agents are rate-limited per tier
- HTTP requests are rate-limited per agent (authenticated) or IP (unauthenticated)
- Rate-limited agents are excluded from Scheduler's assignment pool
- identify message bypasses rate limiting (agent_id unknown)
- Warning frames sent at 80% usage on WebSocket
- 429 responses include Retry-After header and structured JSON error
- No regressions in existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/15-rate-limiting/15-02-SUMMARY.md`
</output>
