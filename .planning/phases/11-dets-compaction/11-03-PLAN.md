---
phase: 11-dets-compaction
plan: 03
type: execute
wave: 3
depends_on: ["11-01", "11-02"]
files_modified:
  - lib/agent_com/endpoint.ex
  - lib/agent_com/dashboard_state.ex
  - lib/agent_com/dashboard_socket.ex
  - lib/agent_com/dashboard_notifier.ex
autonomous: true
must_haves:
  truths:
    - "Operators can manually compact a specific table or all tables via API"
    - "Operators can force-restore a table from backup via API"
    - "Dashboard shows compaction history log with time, table, result, duration"
    - "Push notifications fire on compaction failures and auto-restores only"
  artifacts:
    - path: "lib/agent_com/endpoint.ex"
      provides: "POST /api/admin/compact, POST /api/admin/compact/:table, POST /api/admin/restore/:table endpoints"
      contains: "compact"
    - path: "lib/agent_com/dashboard_state.ex"
      provides: "Compaction history and recovery events in snapshot and health"
      contains: "compaction_history"
    - path: "lib/agent_com/dashboard_socket.ex"
      provides: "Forward compaction_complete and recovery events to browser"
      contains: "compaction_complete"
    - path: "lib/agent_com/dashboard_notifier.ex"
      provides: "Push notifications for compaction failures and auto-restores"
      contains: "compaction_failed"
  key_links:
    - from: "lib/agent_com/endpoint.ex"
      to: "lib/agent_com/dets_backup.ex"
      via: "DetsBackup.compact_all() and DetsBackup.restore_table()"
      pattern: "DetsBackup\\.(compact_all|restore_table)"
    - from: "lib/agent_com/dashboard_state.ex"
      to: "lib/agent_com/dets_backup.ex"
      via: "DetsBackup.compaction_history() in snapshot"
      pattern: "compaction_history"
---

<objective>
Add API endpoints for manual compaction/restore and integrate compaction/recovery events into the dashboard, WebSocket stream, and push notifications.

Purpose: Operators need manual triggers for compaction and restore (locked decisions), dashboard visibility of compaction history (locked decision), and push notifications for failures/auto-restores (locked decision). This completes the operator-facing surface for DETS compaction and recovery.

Output: Three new API endpoints, dashboard snapshot includes compaction history, WebSocket forwards compaction/recovery events, push notifications fire on failures and auto-restores.
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-dets-compaction/11-RESEARCH.md
@.planning/phases/11-dets-compaction/11-01-SUMMARY.md
@.planning/phases/11-dets-compaction/11-02-SUMMARY.md
@.planning/phases/10-dets-backup/10-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add compaction and restore API endpoints</name>
  <files>lib/agent_com/endpoint.ex</files>
  <action>
Add three new admin endpoints to endpoint.ex. Place them in the "Admin: DETS Backup" section after the existing `GET /api/admin/dets-health` route. All require auth via `AgentCom.Plugs.RequireAuth`.

**1. POST /api/admin/compact -- Compact all tables:**
```elixir
post "/api/admin/compact" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    case AgentCom.DetsBackup.compact_all() do
      {:ok, results} ->
        formatted = Enum.map(results, fn r ->
          base = %{"table" => to_string(r.table), "status" => to_string(r.status)}
          base = if r[:duration_ms], do: Map.put(base, "duration_ms", r.duration_ms), else: base
          base = if r[:reason], do: Map.put(base, "reason", to_string(r.reason)), else: base
          base = if r[:retried], do: Map.put(base, "retried", r.retried), else: base
          base
        end)

        compacted = Enum.count(results, fn r -> r.status == :compacted end)
        skipped = Enum.count(results, fn r -> r.status == :skipped end)

        send_json(conn, 200, %{
          "status" => "complete",
          "tables_total" => length(results),
          "tables_compacted" => compacted,
          "tables_skipped" => skipped,
          "results" => formatted
        })
    end
  end
end
```

**2. POST /api/admin/compact/:table -- Compact a specific table:**
Per locked decision: "operators can compact a specific table or all tables on-demand."

Define a mapping from string table names to atoms at the top of the relevant section or as a module attribute. Use the existing @tables list pattern or define inline:
```elixir
post "/api/admin/compact/:table_name" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    table_atoms = %{
      "task_queue" => :task_queue,
      "task_dead_letter" => :task_dead_letter,
      "agent_mailbox" => :agent_mailbox,
      "message_history" => :message_history,
      "agent_channels" => :agent_channels,
      "channel_history" => :channel_history,
      "agentcom_config" => :agentcom_config,
      "thread_messages" => :thread_messages,
      "thread_replies" => :thread_replies
    }

    case Map.get(table_atoms, table_name) do
      nil ->
        send_json(conn, 404, %{"error" => "unknown_table", "table" => table_name})
      table_atom ->
        # Use DetsBackup's internal compact logic by calling compact_all with a filter
        # Or add a compact_table/1 public API to DetsBackup
        # For simplicity, call compact_all and filter (tables are small, serial is fast)
        case AgentCom.DetsBackup.compact_all() do
          {:ok, results} ->
            table_result = Enum.find(results, fn r -> r.table == table_atom end)
            if table_result do
              send_json(conn, 200, %{
                "table" => table_name,
                "status" => to_string(table_result.status),
                "duration_ms" => table_result[:duration_ms] || 0
              })
            else
              send_json(conn, 500, %{"error" => "table_not_in_results"})
            end
        end
    end
  end
end
```

Actually, this is inefficient -- compacting all 9 tables when only 1 is requested. Better approach: add a `compact_one/1` public API to DetsBackup. But to avoid modifying dets_backup.ex in this plan (file ownership concern), use a simpler approach: call the owning GenServer directly from the endpoint, similar to how DetsBackup does it internally.

REVISED approach: Add a `compact_one/1` function call. Since Plan 01 already added the orchestration to DetsBackup, add this public API there in this plan. This is acceptable since this plan depends on Plan 01 and needs to extend DetsBackup minimally.

In `lib/agent_com/dets_backup.ex`, add:
```elixir
@doc "Compact a single DETS table. Returns {:ok, result} or {:error, reason}."
def compact_one(table_atom) when table_atom in @tables do
  GenServer.call(__MODULE__, {:compact_one, table_atom}, 60_000)
end
```

And the handle_call:
```elixir
@impl true
def handle_call({:compact_one, table_atom}, _from, state) do
  result = compact_table(table_atom)
  now = System.system_time(:millisecond)

  formatted = case result do
    {:compacted, duration} -> %{table: table_atom, status: :compacted, duration_ms: duration}
    {:skipped, reason, _} -> %{table: table_atom, status: :skipped, reason: reason}
    {:error, reason, duration} ->
      # Retry once
      case compact_table(table_atom) do
        {:compacted, retry_duration} ->
          %{table: table_atom, status: :compacted, duration_ms: duration + retry_duration, retried: true}
        {:error, retry_reason, retry_duration} ->
          %{table: table_atom, status: :error, reason: retry_reason, duration_ms: duration + retry_duration}
        {:skipped, skip_reason, _} ->
          %{table: table_atom, status: :skipped, reason: skip_reason}
      end
  end

  {:reply, {:ok, formatted}, state}
end
```

Then in endpoint.ex, the single-table compact route becomes:
```elixir
post "/api/admin/compact/:table_name" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    table_atoms = %{
      "task_queue" => :task_queue, "task_dead_letter" => :task_dead_letter,
      "agent_mailbox" => :agent_mailbox, "message_history" => :message_history,
      "agent_channels" => :agent_channels, "channel_history" => :channel_history,
      "agentcom_config" => :agentcom_config, "thread_messages" => :thread_messages,
      "thread_replies" => :thread_replies
    }

    case Map.get(table_atoms, table_name) do
      nil ->
        send_json(conn, 404, %{"error" => "unknown_table", "table" => table_name})
      table_atom ->
        case AgentCom.DetsBackup.compact_one(table_atom) do
          {:ok, result} ->
            send_json(conn, 200, %{
              "table" => table_name,
              "status" => to_string(result.status),
              "duration_ms" => result[:duration_ms] || 0
            })
        end
    end
  end
end
```

**3. POST /api/admin/restore/:table -- Restore a table from backup:**
Per locked decision: "Expose manual restore endpoint -- operators can force-restore a table from backup at any time."
```elixir
post "/api/admin/restore/:table_name" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    table_atoms = %{
      "task_queue" => :task_queue, "task_dead_letter" => :task_dead_letter,
      "agent_mailbox" => :agent_mailbox, "message_history" => :message_history,
      "agent_channels" => :agent_channels, "channel_history" => :channel_history,
      "agentcom_config" => :agentcom_config, "thread_messages" => :thread_messages,
      "thread_replies" => :thread_replies
    }

    case Map.get(table_atoms, table_name) do
      nil ->
        send_json(conn, 404, %{"error" => "unknown_table", "table" => table_name})
      table_atom ->
        case AgentCom.DetsBackup.restore_table(table_atom) do
          {:ok, info} ->
            send_json(conn, 200, %{
              "status" => "restored",
              "table" => table_name,
              "backup_used" => info[:backup_used],
              "record_count" => get_in(info, [:integrity, :record_count]) || 0,
              "file_size" => get_in(info, [:integrity, :file_size]) || 0
            })
          {:error, reason} ->
            send_json(conn, 500, %{
              "status" => "failed",
              "table" => table_name,
              "error" => inspect(reason)
            })
        end
    end
  end
end
```

**4. Update the @moduledoc** at the top of endpoint.ex to include the three new routes.

IMPORTANT: The single-table compact route `/api/admin/compact/:table_name` must be defined AFTER the all-tables `/api/admin/compact` route, otherwise Plug.Router will match the parameterized route first. The order should be:
1. `post "/api/admin/compact"` (all tables)
2. `post "/api/admin/compact/:table_name"` (single table)
3. `post "/api/admin/restore/:table_name"`
  </action>
  <verify>
Run `mix compile --warnings-as-errors` to verify clean compilation. Verify the three new routes exist in endpoint.ex via grep.
  </verify>
  <done>Three new API endpoints exist: POST /api/admin/compact (all tables), POST /api/admin/compact/:table_name (single table), POST /api/admin/restore/:table_name (restore from backup). All require auth and return JSON results.</done>
</task>

<task type="auto">
  <name>Task 2: Integrate compaction/recovery into dashboard, WebSocket, and push notifications</name>
  <files>
    lib/agent_com/dashboard_state.ex
    lib/agent_com/dashboard_socket.ex
    lib/agent_com/dashboard_notifier.ex
  </files>
  <action>
Extend the dashboard infrastructure to display compaction history and handle recovery events.

**1. DashboardState (`dashboard_state.ex`):**

Update the snapshot handle_call to include compaction data. After the existing `dets_health` fetch, add:
```elixir
compaction_history = try do
  AgentCom.DetsBackup.compaction_history()
rescue
  _ -> []
end
```

Add `compaction_history: compaction_history` to the snapshot map.

Also extend `compute_health/3` to include a recovery event condition. After the existing "High DETS Fragmentation" section, add:
```elixir
# 7. Recent auto-restore events (check last compaction history for recovery events)
# This is tracked via PubSub events, not polling. Add a handler for recovery events.
```

Add PubSub handlers for the new events. DashboardState already subscribes to "backups" topic. Add these handle_info clauses BEFORE the catch-all:

```elixir
def handle_info({:compaction_complete, _info}, state) do
  # Compaction complete triggers a snapshot refresh for dashboard clients
  # No state change needed -- compaction_history is fetched live from DetsBackup
  {:noreply, state}
end

def handle_info({:compaction_failed, info}, state) do
  # Track compaction failure as a health condition
  Logger.warning("DetsBackup: compaction failures detected: #{inspect(info.failures)}")
  {:noreply, state}
end

def handle_info({:recovery_complete, info}, state) do
  trigger = info[:trigger] || :unknown
  table = info[:table] || :unknown
  Logger.info("DetsBackup: recovery complete for #{table} (trigger: #{trigger})")
  {:noreply, state}
end

def handle_info({:recovery_failed, info}, state) do
  table = info[:table] || :unknown
  Logger.error("DetsBackup: recovery failed for #{table}: #{inspect(info[:reason])}")
  {:noreply, state}
end
```

**2. DashboardSocket (`dashboard_socket.ex`):**

Add handlers for the new PubSub events BEFORE the catch-all `handle_info(_msg, state)`:

```elixir
def handle_info({:compaction_complete, info}, state) do
  formatted = %{
    type: "compaction_complete",
    timestamp: info.timestamp,
    results: Enum.map(info.results, fn r ->
      %{
        table: to_string(r.table),
        status: to_string(r.status),
        duration_ms: r[:duration_ms] || 0
      }
    end)
  }
  {:ok, %{state | pending_events: [formatted | state.pending_events]}}
end

def handle_info({:compaction_failed, info}, state) do
  formatted = %{
    type: "compaction_failed",
    timestamp: info.timestamp,
    failures: Enum.map(info.failures, fn f ->
      %{table: to_string(f.table), reason: to_string(f[:reason] || "unknown")}
    end)
  }
  {:ok, %{state | pending_events: [formatted | state.pending_events]}}
end

def handle_info({:recovery_complete, info}, state) do
  formatted = %{
    type: "recovery_complete",
    timestamp: info.timestamp,
    table: to_string(info.table),
    trigger: to_string(info[:trigger] || "unknown"),
    backup_used: info[:backup_used],
    record_count: info[:record_count] || 0
  }
  {:ok, %{state | pending_events: [formatted | state.pending_events]}}
end

def handle_info({:recovery_failed, info}, state) do
  formatted = %{
    type: "recovery_failed",
    timestamp: info.timestamp,
    table: to_string(info.table),
    reason: inspect(info[:reason])
  }
  {:ok, %{state | pending_events: [formatted | state.pending_events]}}
end
```

**3. DashboardNotifier (`dashboard_notifier.ex`):**

Per locked decision: "Push notifications for failures and auto-restores only -- successful compaction is silent."

Subscribe to "backups" PubSub topic in `init/1` (add after the existing "presence" subscription):
```elixir
Phoenix.PubSub.subscribe(AgentCom.PubSub, "backups")
```

Add handle_info handlers BEFORE the catch-all:

```elixir
def handle_info({:compaction_failed, info}, state) do
  tables = info.failures |> Enum.map(fn f -> to_string(f.table) end) |> Enum.join(", ")
  payload = Jason.encode!(%{
    title: "AgentCom Alert",
    body: "DETS compaction failed: #{tables}",
    icon: "/favicon.ico"
  })
  new_subs = send_to_all(state.subscriptions, payload)
  {:noreply, %{state | subscriptions: new_subs}}
end

def handle_info({:recovery_complete, %{trigger: :auto} = info}, state) do
  # Push notification for auto-restores only (per locked decision)
  payload = Jason.encode!(%{
    title: "AgentCom Alert",
    body: "DETS auto-restore: #{info.table} restored from backup",
    icon: "/favicon.ico"
  })
  new_subs = send_to_all(state.subscriptions, payload)
  {:noreply, %{state | subscriptions: new_subs}}
end

def handle_info({:recovery_failed, info}, state) do
  payload = Jason.encode!(%{
    title: "AgentCom Critical",
    body: "DETS recovery FAILED: #{info.table} -- #{inspect(info[:reason])}",
    icon: "/favicon.ico"
  })
  new_subs = send_to_all(state.subscriptions, payload)
  {:noreply, %{state | subscriptions: new_subs}}
end
```

Note: The existing catch-all `handle_info(_msg, state)` will handle `:compaction_complete` (silent for success -- no push notification), `:recovery_complete` with trigger `:manual` (no push for manual restores), and `:backup_complete` (already handled or falls through).

IMPORTANT: In DashboardNotifier, the new handlers MUST be placed BEFORE the existing catch-all `def handle_info(_msg, state)`, otherwise they will never match. The existing catch-all for DashboardSocket also needs the same ordering.
  </action>
  <verify>
Run `mix compile --warnings-as-errors` to verify clean compilation. Run `mix test --exclude smoke --exclude skip` to verify existing tests still pass. Grep for "compaction_complete" in dashboard_socket.ex and "compaction_failed" in dashboard_notifier.ex to confirm handlers exist.
  </verify>
  <done>Dashboard snapshot includes compaction_history from DetsBackup. WebSocket forwards compaction_complete, compaction_failed, recovery_complete, and recovery_failed events to browser clients. Push notifications fire on compaction failures and auto-restore events only (successful compaction is silent per locked decision).</done>
</task>

</tasks>

<verification>
1. `mix compile --warnings-as-errors` passes
2. `mix test --exclude smoke --exclude skip` passes
3. endpoint.ex contains `POST /api/admin/compact`, `POST /api/admin/compact/:table_name`, `POST /api/admin/restore/:table_name`
4. dashboard_state.ex snapshot includes `compaction_history` key
5. dashboard_socket.ex handles `:compaction_complete`, `:compaction_failed`, `:recovery_complete`, `:recovery_failed` events
6. dashboard_notifier.ex sends push notifications for `:compaction_failed` and `:recovery_complete` (auto trigger only)
</verification>

<success_criteria>
- Manual compaction of all tables or a specific table available via POST API
- Manual restore of any table available via POST API
- Dashboard snapshot includes compaction history for UI rendering
- WebSocket streams compaction and recovery events to browser clients
- Push notifications fire only on failures and auto-restores (not on success)
</success_criteria>

<output>
After completion, create `.planning/phases/11-dets-compaction/11-03-SUMMARY.md`
</output>
