---
phase: 02-task-queue
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - lib/agent_com/socket.ex
  - lib/agent_com/endpoint.ex

autonomous: true

must_haves:
  truths:
    - "Socket task_complete handler delegates to TaskQueue.complete_task with generation fencing"
    - "Socket task_failed handler delegates to TaskQueue.fail_task with retry/dead-letter logic"
    - "Socket task_recovering handler checks TaskQueue state and responds with continue or reassign"
    - "Socket task_progress handler updates TaskQueue updated_at to prevent overdue sweep"
    - "POST /api/tasks submits a task to the persistent queue and returns task_id"
    - "GET /api/tasks/:task_id returns full task record including history and tokens_used"
    - "GET /api/tasks lists queued tasks with optional status/priority filters"
    - "task_assign message includes generation field for fencing"
  artifacts:
    - path: "lib/agent_com/socket.ex"
      provides: "WebSocket handlers wired to TaskQueue for real state management"
      contains: "AgentCom.TaskQueue"
    - path: "lib/agent_com/endpoint.ex"
      provides: "HTTP task API endpoints for submission, querying, and management"
      contains: "api/tasks"
  key_links:
    - from: "lib/agent_com/socket.ex"
      to: "lib/agent_com/task_queue.ex"
      via: "Socket handlers call TaskQueue public API functions"
      pattern: "AgentCom.TaskQueue"
    - from: "lib/agent_com/endpoint.ex"
      to: "lib/agent_com/task_queue.ex"
      via: "HTTP endpoints call TaskQueue public API functions"
      pattern: "AgentCom.TaskQueue"
    - from: "lib/agent_com/socket.ex"
      to: "connected sidecar"
      via: "task_assign message now includes generation field"
      pattern: "generation"
---

<objective>
Wire the TaskQueue GenServer into the Socket (WebSocket) and Endpoint (HTTP) layers so that task lifecycle messages and API requests drive real persistent state changes instead of just logging.

Purpose: Plan 01 built the TaskQueue engine. This plan connects it to the outside world -- Socket handlers delegate to TaskQueue for state management, and HTTP endpoints expose task submission, querying, and management. After this plan, all Phase 2 success criteria are verifiable end-to-end.

Output: Modified `socket.ex` with TaskQueue-backed handlers, modified `endpoint.ex` with task management API.
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-task-queue/02-RESEARCH.md
@.planning/phases/02-task-queue/02-01-SUMMARY.md
@lib/agent_com/socket.ex
@lib/agent_com/endpoint.ex
@lib/agent_com/task_queue.ex
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire Socket task handlers to TaskQueue</name>
  <files>lib/agent_com/socket.ex</files>
  <action>
Replace the Phase 1 stub task handlers in `AgentCom.Socket` with handlers that delegate to `AgentCom.TaskQueue`. The Phase 1 handlers currently just log events and ack -- Phase 2 handlers perform actual state management.

**Changes to existing handlers:**

1. **`task_accepted` handler** -- Currently logs and acks. Keep the log and ack behavior (the sidecar confirmed receipt of assignment). Optionally call `TaskQueue.update_progress(task_id)` to reset the `updated_at` timestamp as a "still alive" signal. No generation check needed here -- acceptance is informational.

Replace:
```elixir
defp handle_msg(%{"type" => "task_accepted", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_accepted", task_id, msg)
  reply = Jason.encode!(%{"type" => "task_ack", "task_id" => task_id, "status" => "accepted"})
  {:push, {:text, reply}, state}
end
```

With:
```elixir
defp handle_msg(%{"type" => "task_accepted", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_accepted", task_id, msg)
  # Update timestamp to signal the task is actively being worked on
  AgentCom.TaskQueue.update_progress(task_id)
  reply = Jason.encode!(%{"type" => "task_ack", "task_id" => task_id, "status" => "accepted"})
  {:push, {:text, reply}, state}
end
```

2. **`task_progress` handler** -- Currently logs only (fire-and-forget). Add `TaskQueue.update_progress(task_id)` to prevent overdue sweep from reclaiming tasks that are actively reporting progress.

Replace:
```elixir
defp handle_msg(%{"type" => "task_progress", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_progress", task_id, msg)
  {:ok, state}
end
```

With:
```elixir
defp handle_msg(%{"type" => "task_progress", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_progress", task_id, msg)
  # Update timestamp to prevent overdue sweep reclamation
  AgentCom.TaskQueue.update_progress(task_id)
  {:ok, state}
end
```

3. **`task_complete` handler** -- Currently just logs and acks. Replace with TaskQueue delegation using generation fencing.

Replace:
```elixir
defp handle_msg(%{"type" => "task_complete", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_complete", task_id, msg)
  reply = Jason.encode!(%{"type" => "task_ack", "task_id" => task_id, "status" => "complete"})
  {:push, {:text, reply}, state}
end
```

With:
```elixir
defp handle_msg(%{"type" => "task_complete", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_complete", task_id, msg)
  generation = msg["generation"] || 0
  result = msg["result"] || %{}
  tokens_used = msg["tokens_used"] || result["tokens_used"]

  case AgentCom.TaskQueue.complete_task(task_id, generation, %{
    result: result,
    tokens_used: tokens_used
  }) do
    {:ok, _task} ->
      reply = Jason.encode!(%{"type" => "task_ack", "task_id" => task_id, "status" => "complete"})
      {:push, {:text, reply}, state}
    {:error, reason} ->
      reply_error("task_complete_failed: #{reason}", state)
  end
end
```

4. **`task_failed` handler** -- Currently just logs and acks. Replace with TaskQueue delegation including retry/dead-letter logic.

Replace:
```elixir
defp handle_msg(%{"type" => "task_failed", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_failed", task_id, msg)
  reply = Jason.encode!(%{"type" => "task_ack", "task_id" => task_id, "status" => "failed"})
  {:push, {:text, reply}, state}
end
```

With:
```elixir
defp handle_msg(%{"type" => "task_failed", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_failed", task_id, msg)
  generation = msg["generation"] || 0
  error = msg["error"] || msg["reason"] || "unknown"

  case AgentCom.TaskQueue.fail_task(task_id, generation, error) do
    {:ok, :retried, _task} ->
      reply = Jason.encode!(%{"type" => "task_ack", "task_id" => task_id, "status" => "retried"})
      {:push, {:text, reply}, state}
    {:ok, :dead_letter, _task} ->
      reply = Jason.encode!(%{"type" => "task_ack", "task_id" => task_id, "status" => "dead_letter"})
      {:push, {:text, reply}, state}
    {:error, reason} ->
      reply_error("task_fail_failed: #{reason}", state)
  end
end
```

5. **`task_recovering` handler** -- Currently always responds with task_reassign. Replace with TaskQueue-aware logic that checks if the task is still assigned to this agent.

Replace:
```elixir
defp handle_msg(%{"type" => "task_recovering", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_recovering", task_id, msg)
  # For Phase 1: respond with task_reassign (hub takes task back)
  # Phase 2 will add intelligence about whether agent is still working
  reply = Jason.encode!(%{"type" => "task_reassign", "task_id" => task_id})
  {:push, {:text, reply}, state}
end
```

With:
```elixir
defp handle_msg(%{"type" => "task_recovering", "task_id" => task_id} = msg, state) do
  log_task_event(state.agent_id, "task_recovering", task_id, msg)

  case AgentCom.TaskQueue.recover_task(task_id) do
    {:ok, :continue, task} ->
      # Task is still assigned to this agent -- tell sidecar to continue
      reply = Jason.encode!(%{
        "type" => "task_continue",
        "task_id" => task_id,
        "generation" => task.generation
      })
      {:push, {:text, reply}, state}
    {:ok, :reassign} ->
      reply = Jason.encode!(%{"type" => "task_reassign", "task_id" => task_id})
      {:push, {:text, reply}, state}
    {:error, :not_found} ->
      reply = Jason.encode!(%{"type" => "task_reassign", "task_id" => task_id})
      {:push, {:text, reply}, state}
  end
end
```

6. **`handle_info({:push_task, task}, state)` handler** -- Add `generation` field to the task_assign message pushed to the sidecar.

Replace:
```elixir
def handle_info({:push_task, task}, state) do
  push = %{
    "type" => "task_assign",
    "task_id" => task["task_id"] || task[:task_id],
    "description" => task["description"] || task[:description] || "",
    "metadata" => task["metadata"] || task[:metadata] || %{},
    "assigned_at" => System.system_time(:millisecond)
  }
  {:push, {:text, Jason.encode!(push)}, state}
end
```

With:
```elixir
def handle_info({:push_task, task}, state) do
  push = %{
    "type" => "task_assign",
    "task_id" => task["task_id"] || task[:task_id],
    "description" => task["description"] || task[:description] || "",
    "metadata" => task["metadata"] || task[:metadata] || %{},
    "generation" => task["generation"] || task[:generation] || 0,
    "assigned_at" => System.system_time(:millisecond)
  }
  {:push, {:text, Jason.encode!(push)}, state}
end
```

7. **Update `@moduledoc`** -- Update the task_assign documentation to include the `generation` field:
```
  <- {"type": "task_assign", "task_id": "task-abc123", "description": "...", "metadata": {...}, "generation": 1, "assigned_at": 1234567890}
```

And update the task_complete/task_failed docs to show the generation field:
```
  -> {"type": "task_complete", "task_id": "task-abc123", "generation": 1, "result": {...}, "tokens_used": 150}
  -> {"type": "task_failed", "task_id": "task-abc123", "generation": 1, "error": "..."}
```

**Important:** Keep the `log_task_event` helper and PubSub broadcast as-is. The TaskQueue also broadcasts events, but the Socket-level broadcast provides agent_id context that TaskQueue doesn't have.
  </action>
  <verify>
1. Run `mix compile` -- should compile with no errors
2. Verify TaskQueue calls: `grep -c "AgentCom.TaskQueue" lib/agent_com/socket.ex` -- should show 5+ matches (complete_task, fail_task, update_progress x2, recover_task)
3. Verify generation field in push_task: `grep "generation" lib/agent_com/socket.ex` -- should match in handle_info push_task and task_complete/task_failed handlers
4. Verify stale generation handling: `grep "stale_generation\|task_complete_failed\|task_fail_failed" lib/agent_com/socket.ex` -- should match error paths
  </verify>
  <done>All Socket task handlers delegate to TaskQueue for real state management. task_complete and task_failed validate generation for fencing. task_recovering checks TaskQueue state to decide continue vs reassign. task_progress and task_accepted update timestamps to prevent false overdue reclamation. task_assign messages include generation field for the sidecar to echo back.</done>
</task>

<task type="auto">
  <name>Task 2: Add HTTP task management API endpoints</name>
  <files>lib/agent_com/endpoint.ex</files>
  <action>
Add new HTTP endpoints to `AgentCom.Endpoint` for task queue management. These endpoints provide the API-02 requirement (tokens_used in task history) and enable external task submission, monitoring, and dead-letter management.

**Add the following endpoints BEFORE the catch-all `match _` route and AFTER the existing admin push-task route:**

1. **POST /api/tasks** -- Submit a task to the persistent queue (auth required):
```elixir
post "/api/tasks" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    agent_id = conn.assigns[:authenticated_agent]
    params = conn.body_params

    case params do
      %{"description" => description} ->
        task_params = %{
          description: description,
          priority: params["priority"] || "normal",
          metadata: params["metadata"] || %{},
          max_retries: params["max_retries"] || 3,
          complete_by: params["complete_by"],
          submitted_by: agent_id
        }

        case AgentCom.TaskQueue.submit(task_params) do
          {:ok, task} ->
            send_json(conn, 201, %{
              "status" => "queued",
              "task_id" => task.id,
              "priority" => task.priority,
              "created_at" => task.created_at
            })
        end

      _ ->
        send_json(conn, 400, %{"error" => "missing required field: description"})
    end
  end
end
```

2. **GET /api/tasks** -- List tasks with optional filters (auth required):
```elixir
get "/api/tasks" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    opts = []
    opts = if s = conn.params["status"], do: [{:status, String.to_existing_atom(s)} | opts], else: opts
    opts = if p = conn.params["priority"], do: [{:priority, p} | opts], else: opts
    opts = if a = conn.params["assigned_to"], do: [{:assigned_to, a} | opts], else: opts

    tasks = AgentCom.TaskQueue.list(opts)
    formatted = Enum.map(tasks, &format_task/1)
    send_json(conn, 200, %{"tasks" => formatted, "count" => length(formatted)})
  end
end
```

Note: Use `String.to_existing_atom/1` for status conversion to prevent atom table exhaustion. Valid statuses (:queued, :assigned, :completed, :failed) are already defined as atoms in TaskQueue. Wrap in a try/rescue to return a 400 error for invalid status strings.

3. **GET /api/tasks/dead-letter** -- List dead-letter tasks (auth required):
```elixir
get "/api/tasks/dead-letter" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    tasks = AgentCom.TaskQueue.list_dead_letter()
    formatted = Enum.map(tasks, &format_task/1)
    send_json(conn, 200, %{"tasks" => formatted, "count" => length(formatted)})
  end
end
```

**IMPORTANT:** This route MUST be defined BEFORE `get "/api/tasks/:task_id"` -- otherwise Plug.Router will match "dead-letter" as a task_id parameter. Plug.Router matches routes in definition order, so specific paths must come first.

4. **GET /api/tasks/stats** -- Queue statistics (auth required):
```elixir
get "/api/tasks/stats" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    stats = AgentCom.TaskQueue.stats()
    send_json(conn, 200, stats)
  end
end
```

5. **GET /api/tasks/:task_id** -- Get single task with full history including tokens_used (auth required, API-02):
```elixir
get "/api/tasks/:task_id" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    case AgentCom.TaskQueue.get(task_id) do
      {:ok, task} ->
        send_json(conn, 200, format_task(task))
      {:error, :not_found} ->
        send_json(conn, 404, %{"error" => "task_not_found", "task_id" => task_id})
    end
  end
end
```

6. **POST /api/tasks/:task_id/retry** -- Retry a dead-letter task (auth required):
```elixir
post "/api/tasks/:task_id/retry" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    case AgentCom.TaskQueue.retry_dead_letter(task_id) do
      {:ok, task} ->
        send_json(conn, 200, %{
          "status" => "requeued",
          "task_id" => task.id,
          "priority" => task.priority
        })
      {:error, :not_found} ->
        send_json(conn, 404, %{"error" => "task_not_found", "task_id" => task_id})
    end
  end
end
```

**Add helper function** `format_task/1` near the bottom of the module (before `send_json`):
```elixir
defp format_task(task) do
  %{
    "id" => task.id,
    "description" => task.description,
    "metadata" => task.metadata,
    "priority" => task.priority,
    "status" => to_string(task.status),
    "assigned_to" => task.assigned_to,
    "assigned_at" => task.assigned_at,
    "generation" => task.generation,
    "retry_count" => task.retry_count,
    "max_retries" => task.max_retries,
    "last_error" => task.last_error,
    "complete_by" => task.complete_by,
    "result" => task.result,
    "tokens_used" => task.tokens_used,
    "submitted_by" => task.submitted_by,
    "created_at" => task.created_at,
    "updated_at" => task.updated_at,
    "history" => Enum.map(task.history || [], fn
      {event, timestamp, details} ->
        %{"event" => to_string(event), "timestamp" => timestamp, "details" => format_details(details)}
      other -> other
    end)
  }
end

defp format_details(details) when is_map(details) do
  Map.new(details, fn {k, v} -> {to_string(k), v} end)
end
defp format_details(details), do: details
```

This format ensures:
- Atom status/event values are converted to strings for JSON serialization
- Task history with tokens_used is exposed (API-02 requirement)
- All fields are serializable by Jason

**Update `@moduledoc`** to document the new endpoints:
```
- POST   /api/tasks             --- Submit a task to the queue (auth required)
- GET    /api/tasks             --- List tasks with optional filters (auth required)
- GET    /api/tasks/dead-letter --- List dead-letter tasks (auth required)
- GET    /api/tasks/stats       --- Queue statistics (auth required)
- GET    /api/tasks/:task_id    --- Get task details with history (auth required)
- POST   /api/tasks/:task_id/retry --- Retry a dead-letter task (auth required)
```

**Route ordering matters:** The specific routes (`/api/tasks/dead-letter`, `/api/tasks/stats`) MUST be defined BEFORE the parameterized route (`/api/tasks/:task_id`), otherwise Plug.Router will match "dead-letter" and "stats" as task_id parameters.
  </action>
  <verify>
1. Run `mix compile` -- should compile with no errors
2. Verify endpoints exist: `grep -c "api/tasks" lib/agent_com/endpoint.ex` -- should show 6+ matches
3. Verify format_task helper: `grep "format_task" lib/agent_com/endpoint.ex` -- should match
4. Start the hub: `mix run --no-halt`
5. Test task submission:
   ```
   curl -X POST http://localhost:4000/api/tasks \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer <test-token>" \
     -d '{"description": "Test task", "priority": "high"}'
   ```
   Expected: 201 with task_id in response
6. Test task listing:
   ```
   curl -H "Authorization: Bearer <test-token>" http://localhost:4000/api/tasks
   ```
   Expected: 200 with tasks array containing the submitted task
7. Test task get with history:
   ```
   curl -H "Authorization: Bearer <test-token>" http://localhost:4000/api/tasks/<task-id-from-step-5>
   ```
   Expected: 200 with full task record including history
8. Test dead-letter list:
   ```
   curl -H "Authorization: Bearer <test-token>" http://localhost:4000/api/tasks/dead-letter
   ```
   Expected: 200 with empty tasks array
9. Restart the hub and repeat step 6 -- task should still be there (persistence verification)
  </verify>
  <done>HTTP API provides complete task management: POST /api/tasks submits tasks to the persistent queue, GET /api/tasks lists with filters, GET /api/tasks/:task_id returns full task with history including tokens_used (API-02), GET /api/tasks/dead-letter shows failed tasks, POST /api/tasks/:task_id/retry re-queues dead-letter tasks, GET /api/tasks/stats shows queue statistics. All endpoints require authentication.</done>
</task>

</tasks>

<verification>
- `mix compile` succeeds with no errors
- Socket task_complete/task_failed handlers validate generation and delegate to TaskQueue
- Socket task_recovering checks TaskQueue state instead of always returning reassign
- Socket task_progress updates TaskQueue timestamp to prevent false overdue reclamation
- task_assign message includes generation field
- POST /api/tasks creates persistent tasks
- GET /api/tasks/:task_id returns task with history and tokens_used (API-02)
- GET /api/tasks/dead-letter returns dead-letter tasks
- POST /api/tasks/:task_id/retry moves dead-letter tasks back to queue
- Tasks submitted via API survive hub restart (TASK-01 end-to-end)
- All existing WebSocket and HTTP functionality continues to work unchanged
</verification>

<success_criteria>
The TaskQueue is fully wired into the hub's transport layers. Socket handlers perform real state management with generation fencing. HTTP API provides complete task lifecycle management. All Phase 2 success criteria are verifiable end-to-end: persistence across restarts, priority ordering, retry with dead-letter, overdue reclamation, and tokens_used in task history.
</success_criteria>

<output>
After completion, create `.planning/phases/02-task-queue/02-02-SUMMARY.md`
</output>
