---
phase: 38-ollama-client-hub-routing
plan: 02
type: execute
wave: 2
depends_on: ["38-01"]
files_modified:
  - lib/agent_com/claude_client.ex
  - lib/agent_com/claude_client/prompt.ex
  - lib/agent_com/claude_client/response.ex
autonomous: true

must_haves:
  truths:
    - "ClaudeClient GenServer routes to OllamaClient when config is :ollama and to Cli when config is :claude_cli"
    - "Goal decomposition via OllamaClient produces valid task lists (JSON format, not XML)"
    - "Improvement scanning and proposal generation route through OllamaClient with adapted prompts"
    - "Zero ClaudeClient.Cli calls in production code paths when llm_backend is :ollama"
  artifacts:
    - path: "lib/agent_com/claude_client.ex"
      provides: "Backend routing in handle_call based on :llm_backend config"
    - path: "lib/agent_com/claude_client/prompt.ex"
      provides: "Ollama-specific prompt variants with JSON output format and /no_think"
      exports: ["build/3"]
    - path: "lib/agent_com/claude_client/response.ex"
      provides: "Ollama JSON response parsing alongside existing XML parsing"
      exports: ["parse_ollama/2"]
  key_links:
    - from: "lib/agent_com/claude_client.ex"
      to: "lib/agent_com/ollama_client.ex"
      via: "OllamaClient.chat/2 call in handle_call"
      pattern: "OllamaClient\\.chat"
    - from: "lib/agent_com/claude_client/prompt.ex"
      to: "lib/agent_com/claude_client.ex"
      via: "build/3 called with :ollama backend atom"
      pattern: "Prompt\\.build.*:ollama"
    - from: "lib/agent_com/claude_client/response.ex"
      to: "lib/agent_com/claude_client.ex"
      via: "parse_ollama/2 called for Ollama responses"
      pattern: "Response\\.parse_ollama"
---

<objective>
Route ClaudeClient GenServer through OllamaClient and adapt prompts/response parsing for Qwen3 8B.

Purpose: Replace `claude -p` CLI calls with direct Ollama HTTP calls for all hub FSM LLM operations. The three call sites (GoalOrchestrator.Decomposer, SelfImprovement.LlmScanner, Contemplation) already go through ClaudeClient GenServer, so only the GenServer internals and Prompt/Response modules need changing.
Output: Modified `claude_client.ex` with backend routing, `prompt.ex` with Ollama-specific JSON-format prompts, `response.ex` with Ollama JSON response parsing.
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/38-ollama-client-hub-routing/38-RESEARCH.md
@.planning/phases/38-ollama-client-hub-routing/38-CONTEXT.md
@.planning/phases/38-ollama-client-hub-routing/38-01-SUMMARY.md
@lib/agent_com/claude_client.ex
@lib/agent_com/claude_client/prompt.ex
@lib/agent_com/claude_client/response.ex
@lib/agent_com/ollama_client.ex
@lib/agent_com/goal_orchestrator/decomposer.ex
@lib/agent_com/self_improvement/llm_scanner.ex
@lib/agent_com/contemplation.ex
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add backend routing to ClaudeClient GenServer and Ollama prompt variants</name>
  <files>lib/agent_com/claude_client.ex, lib/agent_com/claude_client/prompt.ex</files>
  <action>
**ClaudeClient GenServer changes (`lib/agent_com/claude_client.ex`):**

1. In `init/1`, add `backend` to state:
```elixir
state = %{
  backend: Application.get_env(:agent_com, :llm_backend, :ollama),
  cli_path: ...,
  model: ...,
  timeout_ms: ...,
  hub_state: :executing
}
```

2. In `handle_call({:invoke, prompt_type, params}, _from, state)`, after budget check passes, replace the Task.async body. The Task.async wrapper and Task.yield timeout pattern STAY (they handle timeout for both backends). Change the inner function:

```elixir
task = Task.async(fn ->
  case state.backend do
    :ollama ->
      invoke_ollama(prompt_type, params)

    :claude_cli ->
      AgentCom.ClaudeClient.Cli.invoke(prompt_type, params, state)
  end
end)
```

3. Add private function `invoke_ollama/2`:
```elixir
defp invoke_ollama(prompt_type, params) do
  prompt = AgentCom.ClaudeClient.Prompt.build(prompt_type, params, :ollama)

  case AgentCom.OllamaClient.chat(prompt) do
    {:ok, %{content: content}} ->
      AgentCom.ClaudeClient.Response.parse_ollama(content, prompt_type)

    {:error, _} = err ->
      err
  end
end
```

4. Update `@moduledoc` to mention Ollama backend support and config-driven routing.

**Prompt module changes (`lib/agent_com/claude_client/prompt.ex`):**

1. Change `build/2` to `build/3` with a default third argument: `def build(prompt_type, params, backend \\ :claude_cli)`. The existing `build/2` calls become the `:claude_cli` path. This preserves backward compatibility.

2. For each prompt type, add an Ollama-specific clause that matches `backend = :ollama`. The Ollama prompts differ from Claude prompts in these ways:
   - Request JSON output instead of XML (smaller models are more reliable with JSON)
   - Include explicit step-by-step instructions
   - End with `/no_think` to suppress Qwen3 thinking blocks
   - Use plain text formatting instead of XML-embedded data

3. Add four Ollama prompt clauses:

**`:decompose` Ollama prompt:**
```
You are a goal decomposition agent. Break down the given goal into small, executable tasks.

GOAL:
Title: {goal.title}
Description: {goal.description}
Success Criteria: {goal.success_criteria}

CONTEXT:
Repository: {context.repo}
Available Files: {comma-separated file list, first 100 files}
Constraints: {context.constraints}

INSTRUCTIONS:
Step 1: Read the goal carefully and understand what needs to be done.
Step 2: Identify 3-8 independent tasks that together complete the goal.
Step 3: Each task must have a clear title, description, success criteria, and dependency list.
Step 4: Use 1-based indices for depends_on references. Tasks with no dependencies use an empty array.
Step 5: Order tasks so dependencies come before dependents.

Respond with ONLY a JSON array. No explanation, no markdown fences, no other text.

[{"title": "...", "description": "...", "success_criteria": "...", "depends_on": []}]

/no_think
```

**`:verify` Ollama prompt:**
```
You are a completion verification agent. Evaluate whether a goal has been fully achieved.

GOAL:
Title: {goal.title}
Description: {goal.description}
Success Criteria: {goal.success_criteria}

RESULTS:
{results summary, files modified, test outcomes}

INSTRUCTIONS:
Step 1: Compare each success criterion against the results.
Step 2: Determine if ALL criteria are met. Partial completion is a fail.
Step 3: List any gaps (missing or incomplete items).

Respond with ONLY a JSON object. No explanation, no markdown fences.

{"verdict": "pass" or "fail", "reasoning": "...", "gaps": [{"description": "...", "severity": "critical" or "minor"}]}

/no_think
```

**`:identify_improvements` Ollama prompt:**
```
You are a codebase improvement agent. Analyze recent changes and identify improvements.

REPOSITORY: {repo name or description}

RECENT DIFF:
{diff text}

INSTRUCTIONS:
Step 1: Read the diff carefully.
Step 2: Identify concrete improvements (refactor, test, docs, dependency, performance).
Step 3: Each improvement must have a clear title, description, category, effort level, and affected files.

Respond with ONLY a JSON array. No explanation, no markdown fences.

[{"title": "...", "description": "...", "category": "refactor|test|docs|dependency|performance", "effort": "small|medium|large", "files": ["path/to/file.ex"]}]

/no_think
```

**`:generate_proposals` Ollama prompt:**
```
You are a contemplation agent generating feature proposals for an autonomous hub system.

TECH STACK: {tech_stack}
CODEBASE: {codebase_summary}
FSM HISTORY: {fsm_history}
OUT OF SCOPE: {out_of_scope}
SCALABILITY: {scalability_summary}
ERRORS: {error_summary}

INSTRUCTIONS:
Step 1: Analyze the system context and identify pain points.
Step 2: Generate up to 3 concrete, actionable feature proposals.
Step 3: Each proposal must be achievable in one milestone phase.
Step 4: Do NOT propose features listed in OUT OF SCOPE.

Respond with ONLY a JSON array. No explanation, no markdown fences.

[{"title": "...", "problem": "...", "solution": "...", "description": "...", "rationale": "...", "why_now": "...", "why_not": "...", "impact": "low|medium|high", "effort": "small|medium|large", "dependencies": ["..."], "related_files": ["path/to/file.ex"]}]

/no_think
```

Use the same private helper functions (goal_to_xml, context_to_xml, etc.) for building the Claude prompts. For Ollama prompts, use plain text formatting -- no XML embedding needed. Create simple helper functions like `goal_to_text(goal)` and `context_to_text(context)` that produce plain text versions.

Keep the existing `build/2` behavior unchanged when `backend` is `:claude_cli` (third arg defaults to `:claude_cli`).
  </action>
  <verify>
`mix compile --warnings-as-errors` passes. `grep "invoke_ollama" lib/agent_com/claude_client.ex` shows routing function. `grep "build.*:ollama" lib/agent_com/claude_client/prompt.ex` shows Ollama prompt variants. Verify that existing tests still pass: `mix test --exclude skip --exclude smoke`.
  </verify>
  <done>
ClaudeClient routes to OllamaClient when config is :ollama. Four Ollama-specific prompt templates produce JSON-format instructions with /no_think. Existing Claude CLI path unchanged.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add Ollama response parsing to Response module</name>
  <files>lib/agent_com/claude_client/response.ex</files>
  <action>
Add `parse_ollama/2` public function to `AgentCom.ClaudeClient.Response` that parses Ollama response content (plain text containing JSON) into the same typed Elixir maps as the existing XML parsers.

**New public function:**
```elixir
@spec parse_ollama(String.t(), atom()) :: {:ok, term()} | {:error, term()}
def parse_ollama(content, prompt_type)
```

Implementation for each prompt type:

**`:decompose`** -- Extract JSON array of task objects
1. Strip any remaining `<think>` blocks (defense in depth -- OllamaClient already strips, but belt and suspenders)
2. `String.trim/1` the content
3. Try `Jason.decode/1` directly first
4. If that fails, try to extract a JSON array using regex: `~r/\[.*\]/s` (find first `[` to last `]`)
5. If JSON array found, map each element to `%{title: ..., description: ..., success_criteria: ..., depends_on: ...}` matching the existing output format from `parse_inner/2`
6. `depends_on` may be integers or strings -- normalize to integer list

**`:verify`** -- Extract JSON object with verdict/reasoning/gaps
1. Strip thinking blocks, trim
2. `Jason.decode/1` or regex extract `~r/\{.*\}/s`
3. Map to `%{verdict: :pass | :fail, reasoning: string, gaps: [%{description: string, severity: string}]}`
4. Normalize verdict string to atom (`:pass` or `:fail`)

**`:identify_improvements`** -- Extract JSON array of improvement objects
1. Strip thinking blocks, trim
2. `Jason.decode/1` or regex extract JSON array
3. Map to `%{title: ..., description: ..., category: ..., effort: ..., files: [...]}`
4. Ensure `files` is always a list (handle string case by splitting on comma)

**`:generate_proposals`** -- Extract JSON array of proposal objects
1. Strip thinking blocks, trim
2. `Jason.decode/1` or regex extract JSON array
3. Map to the same proposal map shape as `parse_proposal_element/1`: `%{title:, problem:, solution:, description:, rationale:, why_now:, why_not:, impact:, effort:, dependencies:, related_files:}`

**Shared helper:**
Add `extract_json/1` private function:
```elixir
defp extract_json(text) do
  cleaned = strip_thinking(text) |> String.trim()
  # Strip markdown code fences
  cleaned = Regex.replace(~r/```(?:json)?\n?/, cleaned, "")
  cleaned = Regex.replace(~r/```\s*$/, cleaned, "", global: true)
  cleaned = String.trim(cleaned)

  case Jason.decode(cleaned) do
    {:ok, result} -> {:ok, result}
    {:error, _} ->
      # Try to extract JSON array or object
      cond do
        String.contains?(cleaned, "[") ->
          case Regex.run(~r/\[.*\]/s, cleaned) do
            [json] -> Jason.decode(json)
            nil -> {:error, :no_json_found}
          end
        String.contains?(cleaned, "{") ->
          case Regex.run(~r/\{.*\}/s, cleaned) do
            [json] -> Jason.decode(json)
            nil -> {:error, :no_json_found}
          end
        true ->
          {:error, :no_json_found}
      end
  end
end
```

Add `strip_thinking/1` private function (same as in OllamaClient -- duplicate is fine for module independence):
```elixir
defp strip_thinking(content) do
  Regex.replace(~r/<think>.*?<\/think>/s, content, "") |> String.trim()
end
```

Error format: All parse errors return `{:error, {:parse_error, reason_string}}` matching existing convention.

Update `@moduledoc` to describe dual parsing capability (XML for Claude CLI, JSON for Ollama).
  </action>
  <verify>
`mix compile --warnings-as-errors` passes. `mix test --exclude skip --exclude smoke` passes (existing tests unchanged). `grep "parse_ollama" lib/agent_com/claude_client/response.ex` confirms new function exists.
  </verify>
  <done>
Response module has parse_ollama/2 handling all 4 prompt types with JSON extraction, markdown fence stripping, thinking block stripping, and consistent error tuples. Existing XML parsing untouched.
  </done>
</task>

</tasks>

<verification>
1. `mix compile --warnings-as-errors` passes
2. `mix test --exclude skip --exclude smoke` passes
3. ClaudeClient.init reads `:llm_backend` config into state
4. ClaudeClient.handle_call dispatches to OllamaClient.chat when backend is :ollama
5. Prompt.build/3 with :ollama produces JSON-format prompts with /no_think
6. Response.parse_ollama/2 handles all 4 prompt types
7. Existing Claude CLI path still works when backend is :claude_cli
8. `grep -r "ClaudeClient.Cli.invoke" lib/ --include="*.ex"` shows it only in claude_client.ex (behind config)
</verification>

<success_criteria>
- Config-driven backend routing: :ollama by default, :claude_cli in test
- All 4 prompt types have Ollama-specific JSON-output variants
- Response parsing handles JSON extraction with fallback regex
- Existing Claude CLI path preserved and functional
- All existing tests pass (no regressions)
- Zero direct ClaudeClient.Cli calls outside of ClaudeClient GenServer
</success_criteria>

<output>
After completion, create `.planning/phases/38-ollama-client-hub-routing/38-02-SUMMARY.md`
</output>
