---
phase: 22-self-verification-loop
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - sidecar/lib/execution/verification-loop.js
  - sidecar/verification.js
autonomous: true

must_haves:
  truths:
    - "executeWithVerification dispatches task, runs verification, and returns on pass/skip/auto_pass without retrying"
    - "When verification fails and retries remain, a corrective prompt is constructed from failed+passed checks and the task is re-dispatched"
    - "When retry budget is exhausted, the loop terminates with partial_pass status and all iteration reports"
    - "Shell executor tasks (target_type sidecar) skip the retry loop entirely -- single execution + single verification, no retries"
    - "Cumulative token counts and cost are tracked across all retry iterations"
    - "runVerification accepts a run_number parameter and includes it in the report"
  artifacts:
    - path: "sidecar/lib/execution/verification-loop.js"
      provides: "Bounded execute-verify-fix loop with corrective prompt construction"
      exports: ["executeWithVerification"]
    - path: "sidecar/verification.js"
      provides: "run_number parameter support in runVerification"
      exports: ["runVerification"]
  key_links:
    - from: "sidecar/lib/execution/verification-loop.js"
      to: "sidecar/lib/execution/dispatcher.js"
      via: "require('./dispatcher').dispatch"
      pattern: "dispatch\\(task"
    - from: "sidecar/lib/execution/verification-loop.js"
      to: "sidecar/verification.js"
      via: "require('../../verification').runVerification"
      pattern: "runVerification\\("
---

<objective>
Create the core verification loop module and parameterize runVerification with run_number.

Purpose: This is the heart of Phase 22 -- a bounded execute-verify-fix loop that wraps the existing dispatch() and runVerification() functions. On verification failure, it constructs a corrective prompt containing both failed and passed checks, then re-dispatches to the same LLM executor. Shell executor tasks are excluded from retries (deterministic, no LLM to correct).

Output: verification-loop.js with executeWithVerification(), buildCorrectiveTask(), buildLoopResult(), and helper functions. Updated verification.js accepting run_number parameter.
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/22-self-verification-loop/22-RESEARCH.md

@sidecar/lib/execution/dispatcher.js
@sidecar/verification.js
@sidecar/lib/execution/cost-calculator.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create verification-loop.js with bounded execute-verify-fix loop</name>
  <files>sidecar/lib/execution/verification-loop.js</files>
  <action>
Create `sidecar/lib/execution/verification-loop.js` implementing:

**executeWithVerification(task, config, onProgress):**
- Read `max_verification_retries` from task (default 0).
- Determine target_type from `task.routing_decision.target_type` (or infer via dispatcher pattern).
- If target_type is `'sidecar'` (ShellExecutor), skip the retry loop entirely: dispatch once, run verification once, return result with single report. No corrective retries for deterministic shell commands.
- For LLM executors (claude, ollama): loop from attempt=0 to maxRetries:
  - If attempt > 0 (retry): call `buildCorrectiveTask()` to augment task description with failure details. Emit `onProgress({ type: 'status', message: 'Verification retry N/M: fixing X failed checks...' })`.
  - Call `dispatch(task, config, onProgress)` to execute.
  - Accumulate tokens/cost from result into cumulative totals via `accumulateCost()`.
  - If execution failed (status !== 'success'), return immediately with `execution_failed` status.
  - Call `runVerification(task, config, attempt + 1)` -- pass run_number = attempt + 1.
  - Push report to reports array.
  - If report.status is 'pass', 'skip', or 'auto_pass': return via `buildLoopResult()` with status 'verified'.
  - If last attempt: return via `buildLoopResult()` with status 'partial_pass'.
  - Otherwise: continue loop (next iteration will build corrective prompt).

**buildCorrectiveTask(originalTask, execResult, lastReport, attempt):**
- Separate checks into failed (status !== 'pass') and passed (status === 'pass').
- Format failed checks: `- {type} ({target}): {STATUS}\n  Output: {truncated output, 500 chars}`.
- Format passed checks: `- {type} ({target}): PASS` (no output needed).
- Construct corrective prompt string:
  ```
  VERIFICATION RETRY {attempt}/{maxRetries}: Your previous work failed verification checks.

  FAILED CHECKS:
  {failureContext}

  PASSED CHECKS (keep these passing):
  {passedContext}

  ORIGINAL TASK:
  {originalDescription}

  YOUR PREVIOUS OUTPUT:
  {truncated execResult.output, 1000 chars}

  Fix the failing verification checks. Focus on the specific failures above.
  Do not re-implement working parts -- only fix what is broken.
  ```
- Return new task object: `{ ...originalTask, description: correctivePrompt, _original_description: originalTask._original_description || originalTask.description, _verification_attempt: attempt }`.

**buildLoopResult(execResult, reports, cumulativeCost, status):**
- Return object with all execResult fields, overriding cost/token fields with cumulative totals, plus:
  - `verification_report`: last report in array (or null)
  - `verification_history`: full reports array
  - `verification_status`: 'verified' | 'partial_pass' | 'execution_failed'
  - `verification_attempts`: reports.length

**accumulateCost(cumulative, result):**
- Add result.tokens_in, result.tokens_out, result.estimated_cost_usd to cumulative totals (handle null/undefined as 0).

**truncate(str, maxLen):**
- Return str if shorter than maxLen, otherwise truncate and append '...(truncated)'.

**countFailures(report):**
- Return count of checks with status !== 'pass'.

Export: `{ executeWithVerification }`.

Use `'use strict'`. Require dispatcher and verification via relative paths (`'./dispatcher'` and `'../../verification'`). Require log via `'../log'`. Log at key points: loop start, retry start, loop complete.
  </action>
  <verify>
    `node -e "const m = require('./sidecar/lib/execution/verification-loop'); console.log(typeof m.executeWithVerification)"` prints "function".
  </verify>
  <done>
    verification-loop.js exports executeWithVerification. It wraps dispatch() + runVerification() in a bounded loop. Corrective prompts include both failed and passed checks. Shell tasks skip retries. Cumulative cost is tracked.
  </done>
</task>

<task type="auto">
  <name>Task 2: Parameterize runVerification with run_number</name>
  <files>sidecar/verification.js</files>
  <action>
Update `runVerification()` in `sidecar/verification.js` to accept an optional third parameter `runNumber` (default 1):

1. Change function signature from `async function runVerification(task, config)` to `async function runVerification(task, config, runNumber)`.
2. Add default: `runNumber = runNumber || 1;` at the top of the function body.
3. Replace all hardcoded `run_number: 1` values with `run_number: runNumber` (there are 5 occurrences: skip report, auto_pass report, timeout report, success report, error report).

This is backward-compatible: existing callers that pass 2 args get run_number=1 (same as today). The verification loop passes the iteration number.
  </action>
  <verify>
    `node -e "const v = require('./sidecar/verification'); console.log(v.runVerification.length)"` prints "3" (3 parameters). Grep for `run_number: 1` in verification.js should return 0 matches (all replaced with `run_number: runNumber`).
  </verify>
  <done>
    runVerification accepts run_number parameter. All report instances use the parameterized value. Backward-compatible with existing 2-arg callers.
  </done>
</task>

</tasks>

<verification>
- `node -e "const m = require('./sidecar/lib/execution/verification-loop'); console.log(typeof m.executeWithVerification)"` outputs "function"
- `node -e "const v = require('./sidecar/verification'); console.log(v.runVerification.length)"` outputs "3"
- No syntax errors when requiring the new module
</verification>

<success_criteria>
- verification-loop.js exists with executeWithVerification exported
- Bounded retry loop with configurable max_verification_retries (default 0)
- Corrective prompt includes both failed and passed checks
- Shell executor tasks skip retry loop
- Cumulative cost tracked across iterations
- runVerification parameterized with run_number
</success_criteria>

<output>
After completion, create `.planning/phases/22-self-verification-loop/22-01-SUMMARY.md`
</output>
