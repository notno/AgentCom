---
phase: 30-goal-decomposition-and-inner-loop
plan: 03
type: execute
wave: 2
depends_on: ["30-01", "30-02"]
files_modified:
  - lib/agent_com/goal_orchestrator.ex
  - lib/agent_com/hub_fsm.ex
  - lib/agent_com/application.ex
  - test/agent_com/goal_orchestrator_test.exs
autonomous: true

must_haves:
  truths:
    - "GoalOrchestrator GenServer subscribes to PubSub tasks and goals topics for event-driven monitoring"
    - "GoalOrchestrator.tick/0 dequeues submitted goals, triggers decomposition, and checks for goals needing verification"
    - "Task completion events aggregate by goal_id and trigger verification when all tasks for a goal are done"
    - "HubFSM calls GoalOrchestrator.tick/0 on every executing state tick"
    - "GoalOrchestrator is added to supervision tree after GoalBacklog but before HubFSM"
    - "LLM calls are non-blocking via Task.async so HubFSM tick is never blocked"
  artifacts:
    - path: "lib/agent_com/goal_orchestrator.ex"
      provides: "Event-driven GenServer orchestrating goal decomposition, monitoring, and verification"
      exports: ["start_link/1", "tick/0", "active_goal_count/0"]
    - path: "lib/agent_com/hub_fsm.ex"
      provides: "Updated HubFSM with GoalOrchestrator.tick/0 call in executing state"
    - path: "lib/agent_com/application.ex"
      provides: "Updated supervision tree with GoalOrchestrator"
    - path: "test/agent_com/goal_orchestrator_test.exs"
      provides: "GoalOrchestrator integration tests"
  key_links:
    - from: "lib/agent_com/goal_orchestrator.ex"
      to: "AgentCom.GoalBacklog.dequeue/0"
      via: "Pops highest-priority submitted goal on tick"
    - from: "lib/agent_com/goal_orchestrator.ex"
      to: "AgentCom.GoalOrchestrator.Decomposer.decompose/1"
      via: "Task.async for non-blocking LLM decomposition"
    - from: "lib/agent_com/goal_orchestrator.ex"
      to: "AgentCom.GoalOrchestrator.Verifier.verify/2"
      via: "Task.async for non-blocking LLM verification"
    - from: "lib/agent_com/goal_orchestrator.ex"
      to: "Phoenix.PubSub tasks topic"
      via: "Subscribes to :task_completed and :task_dead_letter events"
    - from: "lib/agent_com/hub_fsm.ex"
      to: "AgentCom.GoalOrchestrator.tick/0"
      via: "Called on every :executing tick (1s interval)"
---

<objective>
Build the GoalOrchestrator GenServer that ties FileTree, DagValidator, Decomposer, and Verifier together into the autonomous inner loop. Wire it into HubFSM's executing tick and the supervision tree.

Purpose: This is the central orchestration module that makes the hub autonomous. It dequeues goals, triggers LLM decomposition, monitors task completion via PubSub, and triggers LLM verification -- all without blocking the HubFSM tick.

Output: GoalOrchestrator GenServer, updated HubFSM, updated supervision tree.
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/30-goal-decomposition-and-inner-loop/30-RESEARCH.md
@.planning/phases/30-goal-decomposition-and-inner-loop/30-01-SUMMARY.md
@.planning/phases/30-goal-decomposition-and-inner-loop/30-02-SUMMARY.md
@lib/agent_com/hub_fsm.ex
@lib/agent_com/goal_backlog.ex
@lib/agent_com/task_queue.ex
@lib/agent_com/application.ex
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement GoalOrchestrator GenServer</name>
  <files>lib/agent_com/goal_orchestrator.ex, test/agent_com/goal_orchestrator_test.exs</files>
  <action>
Create `AgentCom.GoalOrchestrator` as a GenServer following existing patterns (Logger.metadata, PubSub subscribe).

**State struct:**
```elixir
defstruct active_goals: %{},           # goal_id => %{phase: atom, task_ref: reference | nil}
          verification_retries: %{},    # goal_id => integer (0, 1, 2)
          pending_async: nil            # {ref, goal_id, operation} | nil -- tracks one in-flight Task.async
```

**`init/1`:**
- Subscribe to PubSub "tasks" and "goals" topics.
- Initialize empty state.
- Log `goal_orchestrator_started`.

**`tick/0`** (cast) -- Called by HubFSM every 1s. The tick handler should:

1. **If there's a pending async task:** Check if it completed (via `Process.info(ref)` or track Task refs). If the async task sent a message, it will be handled by `handle_info`. Skip further work this tick. This ensures only ONE LLM call is in flight at a time (respects ClaudeClient serialization).

2. **Check for goals needing verification:** Iterate `active_goals` looking for any with `phase: :ready_to_verify`. If found, start async verification:
   ```elixir
   goal_id = ...
   {:ok, goal} = AgentCom.GoalBacklog.get(goal_id)
   retries = Map.get(state.verification_retries, goal_id, 0)
   task_ref = Task.async(fn -> Verifier.verify(goal, retries) end)
   ```
   Track the task_ref in `pending_async`. Transition goal to `:verifying` via GoalBacklog.transition/3.

3. **Check for goals needing decomposition:** Call `AgentCom.GoalBacklog.dequeue/0`. If `{:ok, goal}`:
   - Add to `active_goals` with `phase: :decomposing`.
   - Start async decomposition:
     ```elixir
     task_ref = Task.async(fn -> Decomposer.decompose(goal) end)
     ```
   - Track the task_ref in `pending_async`.

4. **Priority order:** Verify before decompose (verification unlocks completed goals; decomposition creates new work).

**PubSub event handlers (`handle_info`):**

- `{:task_event, %{event: :task_completed, task: task}}` -- If task has a `goal_id` that's in `active_goals`:
  - Call `AgentCom.TaskQueue.goal_progress(goal_id)`.
  - If `progress.pending == 0 and progress.failed == 0` (all done):
    - Update `active_goals[goal_id].phase` to `:ready_to_verify`.
    - Log "all_tasks_complete_for_goal".
  - If `progress.failed > 0 and progress.pending == 0` (some failed, none pending):
    - Treat as ready to verify (verifier will see failures and may create follow-ups).

- `{:task_event, %{event: :task_dead_letter, task: task}}` -- Same logic as task_completed (check if all tasks for the goal are now done/dead).

- Task.async result messages (`{ref, result}` and `{:DOWN, ref, ...}`):
  - On decomposition success `{:ok, task_ids}`:
    - Update `active_goals[goal_id].phase` to `:executing`.
    - Transition goal via `GoalBacklog.transition(goal_id, :executing, child_task_ids: task_ids)`.
    - Clear `pending_async`.
    - Emit telemetry `[:agent_com, :goal, :decomposed]` with task count.
  - On decomposition failure `{:error, reason}`:
    - Transition goal to `:failed` with reason.
    - Remove from `active_goals`.
    - Clear `pending_async`.
    - Log error.
  - On verification success `{:ok, :pass}`:
    - Transition goal to `:complete`.
    - Remove from `active_goals` and `verification_retries`.
    - Clear `pending_async`.
    - Emit telemetry `[:agent_com, :goal, :verified]`.
  - On verification needs_human_review `{:ok, :needs_human_review}`:
    - Transition goal to `:failed` with reason "needs_human_review: max verification retries exceeded".
    - Remove from `active_goals`.
    - Clear `pending_async`.
  - On verification fail with gaps `{:ok, :fail, gaps}`:
    - Call `Verifier.create_followup_tasks(goal, gaps)`.
    - Increment `verification_retries[goal_id]`.
    - Transition goal back to `:executing`.
    - Update `active_goals[goal_id].phase` to `:executing`.
    - Clear `pending_async`.
  - On verification error `{:error, reason}`:
    - Log error, keep goal in current state, clear `pending_async` (will retry on next tick).

**`active_goal_count/0`** (call) -- Returns the count of active goals. Used by HubFSM predicates to know if orchestration is active.

- Catch-all `handle_info` for unmatched PubSub messages: `{:goal_event, _}`, `{:task_event, _}`, other -- return `{:noreply, state}`.

**Tests:**
- Test that init subscribes to PubSub topics (verify using PubSub.subscribe in test, then broadcast).
- Test active_goal_count/0 returns 0 initially.
- Test the Task.async result handling for decomposition success/failure (send synthetic messages to the GenServer).
- Test the Task.async result handling for verification pass/fail/needs_human_review.
- Test that task completion events update active goal phases.

Use `async: false` (GenServer with PubSub). Start dependencies in test setup: PubSub, GoalBacklog, TaskQueue (follow existing test patterns from hub_fsm_test.exs).
  </action>
  <verify>Run `mix test test/agent_com/goal_orchestrator_test.exs` -- all tests pass.</verify>
  <done>GoalOrchestrator GenServer manages the full inner loop: dequeue -> decompose -> monitor -> verify -> complete/retry/fail. LLM calls are non-blocking via Task.async. PubSub events drive task completion monitoring. Max 2 verification retries enforced.</done>
</task>

<task type="auto">
  <name>Task 2: Wire GoalOrchestrator into HubFSM and supervision tree</name>
  <files>lib/agent_com/hub_fsm.ex, lib/agent_com/application.ex</files>
  <action>
**HubFSM integration:**

In `lib/agent_com/hub_fsm.ex`, update the `:executing` tick handler. Currently, when `Predicates.evaluate/2` returns `:stay`, the FSM does nothing. Add a call to `GoalOrchestrator.tick/0`:

```elixir
# In handle_info(:tick, state) when Predicates returns :stay and fsm_state is :executing
:stay ->
  # Drive goal orchestration
  try do
    AgentCom.GoalOrchestrator.tick()
  catch
    :exit, _ -> :ok   # Safe if GoalOrchestrator not started yet
  end
  state
```

The `try/catch :exit` pattern matches how HubFSM already handles ClaudeClient.set_hub_state/1 calls (safe during startup ordering).

IMPORTANT: Only call `GoalOrchestrator.tick/0` when in `:executing` state AND predicates return `:stay`. Do NOT call it during transitions or in `:resting` state.

**Supervision tree:**

In `lib/agent_com/application.ex`, add `{AgentCom.GoalOrchestrator, []}` to the children list. Position it AFTER `GoalBacklog` and BEFORE `HubFSM`:

```elixir
{AgentCom.GoalBacklog, []},
{AgentCom.GoalOrchestrator, []},   # NEW -- after GoalBacklog, before HubFSM
{AgentCom.HubFSM, []},
```

This ensures GoalOrchestrator is started after its dependencies (GoalBacklog, TaskQueue, ClaudeClient) and before HubFSM starts ticking.

No new tests needed for this task -- the HubFSM integration is a one-line change wrapped in try/catch, and the supervision tree ordering is validated by `mix test` running without startup crashes. The existing `hub_fsm_test.exs` tests should continue to pass since GoalOrchestrator.tick/0 is a cast (fire-and-forget).
  </action>
  <verify>Run `mix compile --warnings-as-errors` -- no warnings. Run `mix test test/agent_com/hub_fsm_test.exs` -- all existing tests pass. Run `mix test` -- full test suite passes (GoalOrchestrator doesn't crash when started in supervision tree).</verify>
  <done>HubFSM calls GoalOrchestrator.tick/0 on every executing state tick. GoalOrchestrator is in the supervision tree after GoalBacklog and before HubFSM. All existing tests continue to pass.</done>
</task>

</tasks>

<verification>
1. `mix test` -- full test suite passes including all new and existing tests
2. `mix compile --warnings-as-errors` -- no warnings
3. GoalOrchestrator starts cleanly in supervision tree
4. HubFSM executing tick drives GoalOrchestrator without blocking
5. Goal lifecycle works end-to-end: submitted -> decomposing -> executing -> verifying -> complete
</verification>

<success_criteria>
- GoalOrchestrator.tick/0 is called on every HubFSM executing tick (1s interval)
- LLM calls never block the tick (Task.async pattern)
- PubSub task completion events drive goal progress monitoring
- Verification retries capped at 2, then needs_human_review
- GoalOrchestrator placed correctly in supervision tree ordering
- All existing tests continue to pass
</success_criteria>

<output>
After completion, create `.planning/phases/30-goal-decomposition-and-inner-loop/30-03-SUMMARY.md`
</output>
