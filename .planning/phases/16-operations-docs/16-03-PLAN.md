---
phase: 16-operations-docs
plan: 03
type: execute
wave: 2
depends_on: ["16-01"]
files_modified:
  - docs/daily-operations.md
  - docs/troubleshooting.md
autonomous: true
must_haves:
  truths:
    - "The daily operations guide documents how to use the dashboard, interpret metrics charts, and read structured logs"
    - "The daily operations guide documents routine maintenance: DETS backup status, compaction, alert thresholds"
    - "The troubleshooting guide is organized by symptom (what you see) not by component"
    - "Each troubleshooting entry includes relevant log lines and jq queries inline with the diagnosis steps"
    - "The troubleshooting guide covers all 9 DETS tables by name in the DETS corruption section"
  artifacts:
    - path: "docs/daily-operations.md"
      provides: "Dashboard, metrics, logging, and maintenance guide"
      contains: "metrics"
    - path: "docs/troubleshooting.md"
      provides: "Symptom-based failure diagnosis and recovery"
      contains: "symptom"
  key_links:
    - from: "docs/daily-operations.md"
      to: "docs/architecture.md"
      via: "cross-reference for component context"
      pattern: "architecture"
    - from: "docs/troubleshooting.md"
      to: "docs/architecture.md"
      via: "cross-reference for component context"
      pattern: "architecture"
    - from: "docs/troubleshooting.md"
      to: "AgentCom module docs"
      via: "backtick cross-references"
      pattern: "AgentCom\\."
---

<objective>
Create the daily operations and troubleshooting guides covering monitoring, maintenance, and symptom-based failure diagnosis.

Purpose: Satisfies OPS-02 (dashboard usage, metrics interpretation, log reading, alert response) and OPS-03 (troubleshooting common failure modes with step-by-step recovery). These two guides cover everything an operator does with a running system.

Output: docs/daily-operations.md, docs/troubleshooting.md
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-operations-docs/16-RESEARCH.md
@.planning/phases/16-operations-docs/16-01-SUMMARY.md
@lib/agent_com/metrics_collector.ex
@lib/agent_com/alerter.ex
@lib/agent_com/dets_backup.ex
@lib/agent_com/dashboard.ex
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create daily operations guide</name>
  <files>docs/daily-operations.md</files>
  <action>
Create `docs/daily-operations.md` -- the guide for monitoring and maintaining a running system.

**Writing style per locked decisions:** Narrative walkthrough with WHY explanations. Solo operator audience. Include architecture rationale in each major section.

**Structure the document as follows:**

## 1. Dashboard Overview
- URL: `http://localhost:4000/dashboard`
- What each section shows: agent cards, task queue status, system metrics
- WebSocket connection indicator (connection dot in header)
- Auto-refresh via WebSocket (no polling needed) -- explain WHY this design
- Push notifications: how to enable, what triggers them (task events, alerts, backup/compaction failures)
- Cross-reference `AgentCom.Dashboard`, `AgentCom.DashboardState`, `AgentCom.DashboardSocket`

## 2. Metrics Interpretation
- Dashboard metrics tab: uPlot charts showing 1-hour rolling window (360 points at 10s intervals)
- `GET /api/metrics` endpoint for programmatic access
- Key metrics to watch and what they mean:
  - **Queue depth** (current/trend): How many tasks waiting. Healthy = near 0 or stable. Growing = agents can't keep up.
  - **Task latency percentiles** (p50/p95/p99): Time from submit to complete. High p99 = some tasks are slow.
  - **Agent utilization**: Percentage of time agents spend working vs idle. High = good use, 100% = saturated.
  - **Error rates** (failure count, failure rate %): Task failures in the window. Spikes indicate systemic issues.
  - **Throughput** (completed/hour): Tasks flowing through the system. Baseline for capacity planning.
- Cross-reference `AgentCom.MetricsCollector` for metric definitions

## 3. Reading Structured Logs
- Log file location: `priv/logs/agent_com.log` (JSON format, 10MB x 5 rotation)
- Console output is also JSON (LoggerJSON)
- Key fields in every log entry: `message`, `metadata.module`, `metadata.request_id`, `metadata.agent_id`, `metadata.task_id`, `severity`
- Useful jq queries for common scenarios:
  - All errors: `jq 'select(.severity == "error")' priv/logs/agent_com.log`
  - Activity for a specific agent: `jq 'select(.metadata.agent_id == "my-agent")' priv/logs/agent_com.log`
  - Task lifecycle events: `jq 'select(.telemetry_event | startswith("agent_com.task"))' priv/logs/agent_com.log`
  - Scheduler activity: `jq 'select(.telemetry_event == "agent_com.scheduler.attempt")' priv/logs/agent_com.log`
- Changing log level at runtime: `PUT /api/admin/log-level` with `{"level":"debug"}` (resets on restart per locked decision from Phase 13-03)
- Sidecar logs: `~/.agentcom/<agent-name>/sidecar.log` or `pm2 logs agentcom-<name>`
- Cross-reference `AgentCom.Telemetry` for the full event catalog

## 4. Alerts
- How alerting works: Alerter checks metrics on a periodic schedule, fires alerts via PubSub when thresholds exceeded
- Dashboard shows alert banner (highest severity across unacknowledged alerts)
- Five alert rules -- document each with: what it means, why it matters, what to do:
  - **queue_growing** (WARNING): Queue depth increasing 3+ consecutive checks. Means tasks arriving faster than completion. Check agent availability.
  - **high_failure_rate** (WARNING): >50% failure rate. Means most tasks are failing. Check agent logs/wake commands.
  - **stuck_tasks** (CRITICAL): Tasks assigned >5 minutes without progress. Means agent or sidecar hung. Check sidecar process.
  - **no_agents_online** (CRITICAL): All agents disconnected. System cannot process tasks. Check network/sidecars.
  - **high_error_rate** (WARNING): >10 failures/hour. Means elevated error count. Check for patterns in failures.
- Acknowledging alerts: Dashboard button or `POST /api/alerts/:rule_id/acknowledge`
- Configuring thresholds: `GET/PUT /api/config/alert-thresholds` -- changes take effect next check cycle, no restart needed
- Cross-reference `AgentCom.Alerter`

## 5. Routine Maintenance
- **DETS Backup**: Automatic daily backup to `priv/backups/`. Verify via `GET /api/admin/dets-health` (check last_backup timestamp). Manual trigger: `POST /api/admin/backup`.
- **DETS Compaction**: Automatic every 6 hours (configurable). Check fragmentation via health endpoint. Manual trigger: `POST /api/admin/compact`. Single table: `POST /api/admin/compact/:table`.
- **Log rotation**: Automatic (10MB x 5 files, compressed). No manual intervention needed.
- **Token management**: List with `GET /admin/tokens`, revoke with `DELETE /admin/tokens/:id`.
- **Config management**: Runtime config via `AgentCom.Config` DETS store. Alert thresholds, heartbeat interval, mailbox retention configurable via API.
- Cross-reference `AgentCom.DetsBackup`, `AgentCom.Config`

## 6. API Quick Reference
A compact table of all HTTP endpoints grouped by function (not auth requirement):
- Task management: POST/GET /api/tasks, dead-letter, retry, stats
- Agent management: GET /api/agents
- System admin: backup, compact, restore, log-level, reset
- Configuration: alert-thresholds, heartbeat-interval, mailbox-retention, default-repo
- Monitoring: health, metrics, alerts, dashboard/state, schemas

Include auth requirement (Bearer token or none) and HTTP method for each. This is a reference table, not full documentation -- operators know the APIs exist and can find details in module docs.
  </action>
  <verify>
Run `mix docs` and verify:
1. Daily operations guide appears in sidebar under "Operations Guide"
2. Cross-references to module docs resolve
3. jq examples use correct JSON field paths matching actual LoggerJSON output
4. All 5 alert rules documented
5. API quick reference covers all endpoints from RESEARCH.md
  </verify>
  <done>docs/daily-operations.md covers dashboard usage, metrics interpretation, log reading, alert management, routine maintenance, and API reference for a running system.</done>
</task>

<task type="auto">
  <name>Task 2: Create troubleshooting guide</name>
  <files>docs/troubleshooting.md</files>
  <action>
Create `docs/troubleshooting.md` -- the symptom-based failure diagnosis guide.

**Writing style per locked decisions:** Symptom-based organization (what you see, not what component broke). Log interpretation inline with each symptom -- relevant log lines and jq queries as part of diagnosis steps, NOT a separate section. Narrative explanations of WHY each failure happens.

**Structure the document as follows:**

## Introduction
Brief explanation of the symptom-based organization. How to use this guide: find what you're seeing, follow the diagnosis path, apply the fix.

## HIGH Priority Failures (full diagnosis paths)

### Tasks Stuck in Pending
- **What you see:** Tasks show "queued" on dashboard indefinitely, never assigned
- **Why this happens:** Scheduler needs both queued tasks AND idle agents to make assignments
- **Diagnosis steps:**
  1. Check agent availability: `GET /api/agents` -- are any agents connected and idle?
  2. Check capability match: compare task's `needed_capabilities` with agent's `capabilities`
  3. Check scheduler logs: `jq 'select(.telemetry_event == "agent_com.scheduler.attempt") | {idle: .measurements.idle_agents, queued: .measurements.queued_tasks}' priv/logs/agent_com.log`
  4. If idle_agents is 0: no agents available -- see "Agent Shows Offline" below
  5. If idle_agents > 0 but tasks not assigned: capability mismatch or scheduler not running
- **Fix:** Connect more agents, fix capability declarations, or restart hub if scheduler appears stuck
- Cross-reference `AgentCom.Scheduler`

### Agent Shows Offline / Keeps Disconnecting
- **What you see:** Agent appears briefly then disappears from dashboard, or never appears
- **Why this happens:** Multiple possible causes from auth to network to process lifecycle
- **Diagnosis steps:**
  1. Check sidecar is running: `pm2 list` -- look for agentcom-<name> status
  2. Check sidecar logs: `pm2 logs agentcom-<name>` or check `~/.agentcom/<name>/sidecar.log`
  3. Check for auth errors: `jq 'select(.type == "error" and .error == "invalid_token")' ~/.agentcom/<name>/sidecar.log`
  4. Check for Reaper eviction (stale heartbeat): `jq 'select(.message == "reaper_evict_stale") | {agent: .agent_id, stale_ms: .stale_ms}' priv/logs/agent_com.log`
  5. If token error: re-register agent or check config.json has correct token
  6. If Reaper eviction (60s+ stale): sidecar not sending pings -- check if sidecar process is alive but network blocked
- **Fix:** Restart sidecar (`pm2 restart agentcom-<name>`), fix token, check network
- Cross-reference `AgentCom.Auth`, `AgentCom.Reaper`, `AgentCom.Presence`

### DETS Corruption / Table Unavailable
- **What you see:** API returns errors for task/message operations, dashboard shows errors, logs contain DETS read/write errors
- **Why this happens:** Unclean shutdown (kill -9, power loss), disk full, or concurrent non-OTP access to .dets files
- **All 9 DETS tables** (any can be affected):
  - `task_queue` (TaskQueue) -- Active tasks
  - `task_dead_letter` (TaskQueue) -- Failed tasks
  - `agent_mailbox` (Mailbox) -- Agent messages
  - `message_history` (MessageHistory) -- Message archive
  - `agent_channels` (Channels) -- Channel metadata
  - `channel_history` (Channels) -- Channel messages
  - `agentcom_config` (Config) -- Runtime configuration
  - `thread_messages` (Threads) -- Thread tracking
  - `thread_replies` (Threads) -- Thread reply chains
- **Diagnosis steps:**
  1. Check DETS health: `GET /api/admin/dets-health` -- look for error states
  2. Check hub logs for corruption events: `jq 'select(.message == "dets_corruption_detected") | {table: .table, action: .action}' priv/logs/agent_com.log`
  3. DetsBackup auto-detects corruption and attempts auto-restore from backup
  4. Check auto-restore result: `jq 'select(.message | test("dets_auto_restore"))' priv/logs/agent_com.log`
- **Manual recovery:**
  1. Restore from backup: `POST /api/admin/restore/<table_name>` -- restores from latest backup
  2. If no backup exists: DetsBackup deletes corrupted file, GenServer restarts with empty table (degraded mode)
  3. Verify: `GET /api/admin/dets-health` should show healthy status
- **Prevention:** Ensure clean shutdown (Ctrl+C in iex, or `System.stop()`). Regular backups (automatic, but verify via health endpoint).
- Cross-reference `AgentCom.DetsBackup`

### Queue Backlog Growing
- **What you see:** Alert fires for `queue_growing`, queue depth increasing on metrics chart
- **Why this happens:** Task inflow exceeds agent processing capacity
- **Diagnosis steps:**
  1. Check metrics: `GET /api/metrics` -- look at `queue_depth.current` and `queue_depth.trend`
  2. Check agent utilization -- are agents working at capacity?
  3. Check failure rate -- are tasks failing and retrying, consuming agent time?
  4. `jq 'select(.telemetry_event == "agent_com.task.complete" or .telemetry_event == "agent_com.task.fail") | {event: .telemetry_event, task: .metadata.task_id}' priv/logs/agent_com.log | tail -20`
- **Fix:** Add more agents (`node sidecar/add-agent.js --hub http://localhost:4000 --name new-agent`). Fix failing wake commands. Reduce task submission rate.
- Cross-reference `AgentCom.MetricsCollector`

## MEDIUM Priority Failures

### Stuck Tasks (Assigned but Not Completing)
- **What you see:** Alert fires for `stuck_tasks` (CRITICAL), tasks show "assigned" for >5 minutes on dashboard
- **Why this happens:** Agent's sidecar accepted the task but the wake command is hung, crashing silently, or sidecar lost connection after accepting
- **Diagnosis steps:**
  1. Identify the assigned agent: `GET /api/tasks?status=assigned`
  2. Check sidecar logs for wake command output: `pm2 logs agentcom-<agent-name>`
  3. Check if agent FSM is in "working" state: `GET /api/agents` -- look for the agent's status
  4. Scheduler's 30-second sweep automatically reclaims tasks assigned >5 minutes (configurable stuck threshold)
- **Fix:** Wait for auto-reclaim, or restart the stuck agent's sidecar. Fix wake command if it's consistently failing.
- Cross-reference `AgentCom.Scheduler`, `AgentCom.AgentFSM`

### High Failure Rate
- **What you see:** Alert fires for `high_failure_rate` or `high_error_rate`, dead letter queue growing on dashboard
- **Why this happens:** Wake command broken, agent producing invalid results, or external dependency down
- **Diagnosis steps:**
  1. Check dead letter queue: `GET /api/tasks/dead-letter` -- look for common error patterns
  2. Check sidecar logs for wake command exit codes: `jq 'select(.message | test("wake.*error|wake.*fail"))' ~/.agentcom/<name>/sidecar.log`
  3. Look at error distribution: are all agents failing or just one?
- **Fix:** Fix root cause in wake command or agent configuration. Retry dead-letter tasks: dashboard button or `POST /api/tasks/<task_id>/retry`.
- Cross-reference `AgentCom.TaskQueue`

### Dashboard Not Updating
- **What you see:** Dashboard shows stale data, connection dot shows "Disconnected"
- **Why this happens:** Browser WebSocket connection lost (proxy/firewall), hub crashed, or DashboardState not broadcasting
- **Diagnosis steps:**
  1. Check browser console (F12) for WebSocket errors
  2. Check hub is alive: `curl http://localhost:4000/health`
  3. If health returns ok but dashboard stale: DashboardSocket may need reconnect (refresh page)
  4. If health fails: hub is down -- check for `erl_crash.dump` in project root
- **Fix:** Refresh browser. If hub crashed, restart with `iex -S mix` and check crash dump for OOM or other BEAM errors.
- Cross-reference `AgentCom.DashboardSocket`

## LOW Priority Failures

### Logs Not Appearing or Wrong Format
- **What you see:** Log file empty, not JSON, or missing expected fields
- **Diagnosis:** Check if `priv/logs/` directory exists (created on startup). Check config.exs for logger configuration. Check log level -- `PUT /api/admin/log-level` with `{"level":"debug"}` for maximum verbosity.
- **Fix:** Restart hub (creates priv/logs/ if missing). Verify LoggerJSON is in deps.

### Push Notifications Not Working
- **What you see:** No browser notifications for alerts or task events
- **Diagnosis:** Check browser console for push subscription errors. Check `GET /api/dashboard/vapid-key` returns a key. Ensure browser notification permission is granted.
- **Fix:** VAPID keys auto-generate on first start. Re-enable browser notifications if permission was denied. Refresh dashboard page.

### Compaction Not Running / High Fragmentation
- **What you see:** DETS health shows high fragmentation ratios (>50%) on dashboard health card
- **Diagnosis:** Check `GET /api/admin/dets-health` for fragmentation ratios and last compaction timestamps. Default 6-hour interval may not have elapsed yet.
- **Fix:** Manual compaction: `POST /api/admin/compact` (all tables) or `POST /api/admin/compact/<table>` (single table). Adjust compaction threshold or interval in config if needed.
- Cross-reference `AgentCom.DetsBackup`
  </action>
  <verify>
Run `mix docs` and verify:
1. Troubleshooting guide appears in sidebar under "Operations Guide"
2. Cross-references to module docs resolve
3. All 10 failure modes present (4 HIGH, 3 MEDIUM, 3 LOW)
4. Each HIGH/MEDIUM entry has inline log lines and jq queries (not a separate section)
5. DETS corruption section lists all 9 tables by name
6. Symptom-based organization (headers describe what operator sees, not internal components)
  </verify>
  <done>docs/troubleshooting.md covers 10 failure modes organized by symptom with inline log interpretation, jq queries, diagnosis steps, and recovery procedures. All 9 DETS tables enumerated in the corruption section.</done>
</task>

</tasks>

<verification>
1. `mix docs` completes successfully with all 4 guide files
2. Both guides appear in ExDoc sidebar under "Operations Guide"
3. Cross-references to module docs and architecture guide resolve
4. Daily operations covers: dashboard, metrics, logs, alerts, maintenance, API reference
5. Troubleshooting covers 10 failure modes with symptom-based organization
6. Log interpretation is inline with symptoms (not a separate section)
7. All 9 DETS tables listed by name in troubleshooting
</verification>

<success_criteria>
The daily operations guide enables an operator to monitor the system via dashboard, metrics, and logs, manage alerts, and perform routine maintenance. The troubleshooting guide enables symptom-based diagnosis of the 10 most common failure modes with inline log interpretation and recovery procedures. Together they satisfy OPS-02 and OPS-03.
</success_criteria>

<output>
After completion, create `.planning/phases/16-operations-docs/16-03-SUMMARY.md`
</output>
