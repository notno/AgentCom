---
phase: 10-dets-backup
plan: 02
type: execute
wave: 2
depends_on: ["01"]
files_modified:
  - lib/agent_com/endpoint.ex
  - lib/agent_com/dashboard_state.ex
  - lib/agent_com/dashboard_socket.ex
  - lib/agent_com/dashboard.ex
  - test/dets_backup_test.exs
autonomous: true

must_haves:
  truths:
    - "POST /api/admin/backup triggers manual backup and returns synchronous JSON results"
    - "GET /api/admin/dets-health returns JSON health metrics for all 9 tables"
    - "DashboardState.compute_health includes stale backup and high fragmentation conditions"
    - "Dashboard snapshot includes dets_health key with per-table metrics"
    - "Dashboard UI shows DETS Storage Health panel with table metrics and last backup time"
    - "DashboardSocket forwards backup_complete events to browser clients"
    - "Tests verify health_metrics, backup_all, and retention cleanup"
  artifacts:
    - path: "lib/agent_com/endpoint.ex"
      provides: "Manual backup and DETS health API endpoints"
      contains: "/api/admin/backup"
    - path: "lib/agent_com/dashboard_state.ex"
      provides: "DETS health integrated into compute_health and snapshot"
      contains: "dets_health"
    - path: "lib/agent_com/dashboard_socket.ex"
      provides: "Subscription to backups PubSub topic"
      contains: "backups"
    - path: "lib/agent_com/dashboard.ex"
      provides: "DETS Storage Health panel in dashboard UI"
      contains: "panel-dets"
    - path: "test/dets_backup_test.exs"
      provides: "Unit tests for DetsBackup GenServer"
      contains: "DetsBackupTest"
  key_links:
    - from: "lib/agent_com/endpoint.ex"
      to: "lib/agent_com/dets_backup.ex"
      via: "AgentCom.DetsBackup.backup_all/0 and health_metrics/0"
      pattern: "DetsBackup"
    - from: "lib/agent_com/dashboard_state.ex"
      to: "lib/agent_com/dets_backup.ex"
      via: "AgentCom.DetsBackup.health_metrics/0 in compute_health and snapshot"
      pattern: "DetsBackup"
    - from: "lib/agent_com/dashboard_socket.ex"
      to: "lib/agent_com/dets_backup.ex"
      via: "PubSub backups topic subscription"
      pattern: "backups"
    - from: "lib/agent_com/dashboard.ex"
      to: "lib/agent_com/dashboard_state.ex"
      via: "snapshot.dets_health rendered by renderDetsHealth JS function"
      pattern: "dets_health"
---

<objective>
Wire the DetsBackup GenServer into the HTTP layer (manual backup trigger endpoint, health JSON endpoint) and the dashboard (DETS health card, DashboardState health integration, DashboardSocket real-time updates). Add tests. After this plan, all three requirements (DETS-01, DETS-02, DETS-04) are fully delivered.

Purpose: Completes the user-facing integration so backups are triggerable via API and health is visible in the dashboard.

Output: 2 API endpoints, dashboard integration (state + socket + UI), tests
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-dets-backup/10-RESEARCH.md
@.planning/phases/10-dets-backup/10-CONTEXT.md

@lib/agent_com/endpoint.ex
@lib/agent_com/dashboard_state.ex
@lib/agent_com/dashboard_socket.ex
@lib/agent_com/dashboard.ex
@lib/agent_com/dets_backup.ex
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add API endpoints for manual backup and DETS health</name>
  <files>
    lib/agent_com/endpoint.ex
  </files>
  <action>
Add `POST /api/admin/backup` and `GET /api/admin/dets-health` routes to `lib/agent_com/endpoint.ex`.

Place them AFTER the existing `post "/api/admin/push-task"` block and BEFORE the Task Queue API section. Group them as a new "Admin: DETS Backup" section.

**POST /api/admin/backup** (manual backup trigger, DETS-02):
```elixir
# --- Admin: DETS Backup ---

post "/api/admin/backup" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    case AgentCom.DetsBackup.backup_all() do
      {:ok, results} ->
        formatted = Enum.map(results, fn
          {:ok, info} -> %{"table" => to_string(info.table), "status" => "ok", "path" => info.path, "size" => info.size}
          {:error, info} -> %{"table" => to_string(info.table), "status" => "error", "reason" => to_string(info.reason)}
        end)
        success_count = Enum.count(results, fn {:ok, _} -> true; _ -> false end)
        send_json(conn, 200, %{
          "status" => "complete",
          "tables_total" => length(results),
          "tables_success" => success_count,
          "results" => formatted
        })
    end
  end
end
```

**GET /api/admin/dets-health** (health metrics, DETS-04):
```elixir
get "/api/admin/dets-health" do
  conn = AgentCom.Plugs.RequireAuth.call(conn, [])
  if conn.halted do
    conn
  else
    metrics = AgentCom.DetsBackup.health_metrics()
    formatted_tables = Enum.map(metrics.tables, fn t ->
      %{
        "table" => to_string(t.table),
        "record_count" => t.record_count,
        "file_size_bytes" => t.file_size_bytes,
        "fragmentation_ratio" => t.fragmentation_ratio,
        "status" => to_string(t.status)
      }
    end)

    now = System.system_time(:millisecond)
    stale_backup = case metrics.last_backup_at do
      nil -> true
      ts -> now - ts > 48 * 60 * 60 * 1000
    end
    high_frag = Enum.any?(metrics.tables, fn t -> t.status == :ok and t.fragmentation_ratio > 0.5 end)

    health_status = cond do
      stale_backup and high_frag -> "unhealthy"
      stale_backup or high_frag -> "warning"
      true -> "healthy"
    end

    send_json(conn, 200, %{
      "health_status" => health_status,
      "stale_backup" => stale_backup,
      "high_fragmentation" => high_frag,
      "last_backup_at" => metrics.last_backup_at,
      "tables" => formatted_tables
    })
  end
end
```

Also update the `@moduledoc` route listing at the top of endpoint.ex to include:
```
- POST   /api/admin/backup     — Trigger manual DETS backup (auth required)
- GET    /api/admin/dets-health — DETS table health metrics (auth required)
```
  </action>
  <verify>
Run `mix compile` -- should compile cleanly.
Start the server and test:
- `curl -X POST http://localhost:4000/api/admin/backup -H "Authorization: Bearer TOKEN"` returns 200 with backup results
- `curl http://localhost:4000/api/admin/dets-health -H "Authorization: Bearer TOKEN"` returns 200 with health metrics
  </verify>
  <done>
POST /api/admin/backup endpoint exists, calls DetsBackup.backup_all/0, returns synchronous JSON results with per-table status.
GET /api/admin/dets-health endpoint exists, calls DetsBackup.health_metrics/0, returns JSON health metrics with health_status, stale_backup, high_fragmentation flags.
Both endpoints require RequireAuth authentication.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate DETS health into DashboardState</name>
  <files>
    lib/agent_com/dashboard_state.ex
  </files>
  <action>
Modify `lib/agent_com/dashboard_state.ex` to include DETS health in compute_health and the snapshot.

**In `compute_health/3`**, add two new condition blocks AFTER the existing "Stuck Tasks" check (before the status determination). Read the actual code first to understand the exact variable threading pattern (conditions list, has_critical flag), then add:

```elixir
# 5. Stale DETS Backup
dets_metrics = try do
  AgentCom.DetsBackup.health_metrics()
rescue
  _ -> nil
end

conditions =
  if dets_metrics do
    now_ms = now
    case dets_metrics.last_backup_at do
      nil ->
        ["DETS backup: never run" | conditions]
      ts when now_ms - ts > 48 * 60 * 60 * 1000 ->
        hours_ago = div(now_ms - ts, 3_600_000)
        ["DETS backup stale: last backup #{hours_ago}h ago" | conditions]
      _ ->
        conditions
    end
  else
    conditions
  end

# 6. High DETS Fragmentation
conditions =
  if dets_metrics do
    high_frag_tables = dets_metrics.tables
      |> Enum.filter(fn t -> t.status == :ok and t.fragmentation_ratio > 0.5 end)
      |> Enum.map(fn t -> to_string(t.table) end)

    if length(high_frag_tables) > 0 do
      ["DETS fragmentation >50%: #{Enum.join(high_frag_tables, ", ")}" | conditions]
    else
      conditions
    end
  else
    conditions
  end
```

NOTE: These are warnings, not critical conditions. They should NOT change `has_critical`. Read the existing code first to understand how `has_critical` is threaded and ensure these conditions only append to `conditions` without touching `has_critical`.

**In `handle_call(:snapshot, ...)`**, add `dets_health` to the snapshot map:

After the existing health computation, add:
```elixir
dets_health = try do
  AgentCom.DetsBackup.health_metrics()
rescue
  _ -> nil
end
```

Then add `dets_health: dets_health` to the snapshot map (alongside existing fields like `throughput: throughput`).

The `try/rescue` wrapper handles the case where DetsBackup hasn't started yet or crashes.

**Also subscribe to "backups" PubSub topic** in `init/1`:
```elixir
Phoenix.PubSub.subscribe(AgentCom.PubSub, "backups")
```

The existing catch-all `handle_info(_msg, state)` will absorb backup events without error.
  </action>
  <verify>
Run `mix compile` -- should compile cleanly.
Start the server and check: `curl http://localhost:4000/api/dashboard/state` includes `dets_health` key in response.
  </verify>
  <done>
compute_health/3 includes stale backup condition (>48h or never run) and high fragmentation condition (>50%).
Snapshot includes dets_health key with per-table metrics from DetsBackup.health_metrics/0.
DashboardState subscribes to "backups" PubSub topic.
  </done>
</task>

<task type="auto">
  <name>Task 3: Subscribe DashboardSocket to backups topic</name>
  <files>
    lib/agent_com/dashboard_socket.ex
  </files>
  <action>
Modify `lib/agent_com/dashboard_socket.ex` to subscribe to the "backups" PubSub topic.

In `init/1`, after the existing PubSub subscriptions, add:
```elixir
Phoenix.PubSub.subscribe(AgentCom.PubSub, "backups")
```

Add a handler for the backup_complete message:
```elixir
def handle_info({:backup_complete, info}, state) do
  formatted = %{
    type: "backup_complete",
    timestamp: info.timestamp,
    tables_backed_up: Enum.map(info.tables_backed_up, &to_string/1)
  }

  {:ok, %{state | pending_events: [formatted | state.pending_events]}}
end
```

This follows the exact same pattern as existing `:task_event`, `:agent_joined`, etc. handlers -- accumulate into pending_events, let the flush timer batch-push to the browser.
  </action>
  <verify>
Run `mix compile` -- should compile cleanly.
  </verify>
  <done>
DashboardSocket subscribes to "backups" PubSub topic.
backup_complete events are formatted and pushed to browser via pending_events.
  </done>
</task>

<task type="auto">
  <name>Task 4: Add DETS health card to dashboard UI</name>
  <files>
    lib/agent_com/dashboard.ex
  </files>
  <action>
Modify `lib/agent_com/dashboard.ex` to add the DETS Storage Health panel.

**HTML -- Add a new section after the existing `grid-bottom` div** (after the closing `</div>` of `grid-bottom`, before the `<script>` tag):

```html
<!-- DETS Storage Health -->
<div style="margin-top: 12px;">
  <div class="panel" id="panel-dets">
    <div class="panel-title">DETS Storage Health</div>
    <div class="table-wrap">
      <table id="dets-table">
        <thead>
          <tr>
            <th>Table</th>
            <th>Records</th>
            <th>File Size</th>
            <th>Fragmentation</th>
            <th>Status</th>
          </tr>
        </thead>
        <tbody id="dets-tbody"></tbody>
      </table>
    </div>
    <div style="margin-top: 8px; font-size: 0.8em; color: #888;" id="dets-backup-info">
      Last backup: --
    </div>
    <div class="empty-state" id="dets-empty">No DETS health data</div>
  </div>
</div>
```

**JavaScript -- Add `renderDetsHealth` function** in the script section, after the `renderDeadLetter` function:

```javascript
function renderDetsHealth(detsHealth) {
  var panel = document.getElementById('panel-dets');
  var tbody = document.getElementById('dets-tbody');
  var empty = document.getElementById('dets-empty');
  var backupInfo = document.getElementById('dets-backup-info');

  if (!detsHealth || !detsHealth.tables) {
    tbody.innerHTML = '';
    empty.style.display = 'block';
    backupInfo.textContent = 'Last backup: --';
    return;
  }
  empty.style.display = 'none';

  tbody.innerHTML = detsHealth.tables.map(function(t) {
    var tableName = t.table || '--';
    var records = (t.status === 'ok' || t.status === 'available') ? t.record_count : '--';
    var fileSize = (t.status === 'ok' || t.status === 'available') ? formatFileSize(t.file_size_bytes) : '--';
    var frag = (t.status === 'ok' || t.status === 'available') ? (t.fragmentation_ratio * 100).toFixed(1) + '%' : '--';
    var fragClass = '';
    if (t.fragmentation_ratio > 0.5) fragClass = 'color: #ef4444; font-weight: 600;';
    else if (t.fragmentation_ratio > 0.3) fragClass = 'color: #fbbf24;';

    var statusDot = t.status === 'ok' ? 'ok' : 'offline';

    return '<tr>' +
      '<td>' + escapeHtml(tableName) + '</td>' +
      '<td>' + records + '</td>' +
      '<td>' + fileSize + '</td>' +
      '<td style="' + fragClass + '">' + frag + '</td>' +
      '<td><span class="dot ' + statusDot + '"></span>' + escapeHtml(String(t.status)) + '</td>' +
      '</tr>';
  }).join('');

  if (detsHealth.last_backup_at) {
    backupInfo.textContent = 'Last backup: ' + timeAgo(detsHealth.last_backup_at);
  } else {
    backupInfo.textContent = 'Last backup: never';
  }
}

function formatFileSize(bytes) {
  if (bytes == null) return '--';
  if (bytes < 1024) return bytes + ' B';
  if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB';
  return (bytes / (1024 * 1024)).toFixed(1) + ' MB';
}
```

**Call `renderDetsHealth` from `renderFullState`** -- add after the `renderDeadLetter` call:
```javascript
renderDetsHealth(data.dets_health || null);
```

**Add `backup_complete` to `handleEvents` switch** -- add a case:
```javascript
case 'backup_complete':
  if (dashConn && dashConn.ws && dashConn.ws.readyState === 1) {
    dashConn.ws.send(JSON.stringify({type: 'request_snapshot'}));
  }
  break;
```

**Update the 30-second refresh interval** to also render DETS health:
Add `renderDetsHealth(dashState.dets_health || null);` inside the `if (dashState)` block, after the existing `renderDeadLetter` call.
  </action>
  <verify>
Run `mix compile` -- should compile cleanly.
Visit http://localhost:4000/dashboard -- DETS Storage Health panel should appear.
All 9 tables listed with record counts, file sizes, fragmentation percentages.
"Last backup" info shows correctly.
  </verify>
  <done>
Dashboard includes DETS Storage Health panel with table metrics table.
renderDetsHealth function formats and displays per-table metrics.
formatFileSize helper provides human-readable byte formatting.
backup_complete events trigger snapshot refresh for live updates.
30-second refresh cycle includes DETS health rendering.
  </done>
</task>

<task type="auto">
  <name>Task 5: Add tests for DetsBackup GenServer</name>
  <files>
    test/dets_backup_test.exs
  </files>
  <action>
Create `test/dets_backup_test.exs` with unit tests for the DetsBackup GenServer.

```elixir
defmodule AgentCom.DetsBackupTest do
  use ExUnit.Case, async: false

  test "health_metrics returns data for all 9 tables" do
    metrics = AgentCom.DetsBackup.health_metrics()
    assert is_map(metrics)
    assert is_list(metrics.tables)
    assert length(metrics.tables) == 9

    Enum.each(metrics.tables, fn t ->
      assert Map.has_key?(t, :table)
      assert Map.has_key?(t, :record_count)
      assert Map.has_key?(t, :file_size_bytes)
      assert Map.has_key?(t, :fragmentation_ratio)
      assert Map.has_key?(t, :status)
      assert t.status == :ok
    end)
  end

  test "backup_all creates backup files and returns results" do
    {:ok, results} = AgentCom.DetsBackup.backup_all()
    assert is_list(results)
    assert length(results) == 9

    Enum.each(results, fn result ->
      assert {:ok, info} = result
      assert is_atom(info.table)
      assert is_binary(info.path)
      assert is_integer(info.size)
      assert File.exists?(info.path)
    end)
  end

  test "backup retention keeps only last 3 per table" do
    # Run backup 4 times with different timestamps
    {:ok, _} = AgentCom.DetsBackup.backup_all()
    Process.sleep(1100)
    {:ok, _} = AgentCom.DetsBackup.backup_all()
    Process.sleep(1100)
    {:ok, _} = AgentCom.DetsBackup.backup_all()
    Process.sleep(1100)
    {:ok, _} = AgentCom.DetsBackup.backup_all()

    backup_dir = Application.get_env(:agent_com, :backup_dir, "tmp/test/backups")
    {:ok, files} = File.ls(backup_dir)

    table_atoms = [:task_queue, :task_dead_letter, :agent_mailbox, :message_history,
                   :agent_channels, :channel_history, :agentcom_config, :thread_messages, :thread_replies]

    Enum.each(table_atoms, fn table ->
      prefix = "#{table}_"
      matching = Enum.filter(files, fn f -> String.starts_with?(f, prefix) end)
      assert length(matching) <= 3, "Table #{table} has #{length(matching)} backups, expected <= 3"
    end)
  end
end
```

Note: The retention test uses `Process.sleep(1100)` to ensure each backup gets a different timestamp at second granularity. Tests run against the live application (all 9 DETS tables are open in test env). The backup_dir in test env points to `tmp/test/backups` so production data is never touched.
  </action>
  <verify>
Run `mix test test/dets_backup_test.exs` -- all 3 tests should pass.
  </verify>
  <done>
test/dets_backup_test.exs exists with 3 tests:
- health_metrics returns data for all 9 tables with expected fields
- backup_all creates backup files and returns success results
- backup retention keeps only last 3 per table after 4 runs
  </done>
</task>

</tasks>

<verification>
1. `mix compile --warnings-as-errors` passes
2. `mix test test/dets_backup_test.exs` passes all 3 tests
3. POST /api/admin/backup returns 200 with backup results for 9 tables
4. GET /api/admin/dets-health returns 200 with table metrics and health_status
5. GET /api/dashboard/state includes dets_health key
6. Dashboard shows DETS Storage Health panel with all 9 tables
7. After running backup via API, dashboard updates "Last backup" time
</verification>

<success_criteria>
- POST /api/admin/backup triggers manual backup and returns synchronous JSON results
- GET /api/admin/dets-health returns JSON health metrics for all 9 tables
- DashboardState.compute_health includes stale backup and high fragmentation conditions
- Dashboard snapshot includes dets_health key with per-table metrics
- Dashboard UI shows DETS Storage Health panel with table metrics and last backup time
- DashboardSocket forwards backup_complete events to browser clients
- Tests verify health_metrics, backup_all, and retention cleanup
</success_criteria>

<output>
After completion, create `.planning/phases/10-dets-backup/10-02-SUMMARY.md`
</output>
