---
phase: 14-metrics-alerting
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/agent_com/metrics_collector.ex
  - lib/agent_com/application.ex
  - lib/agent_com/endpoint.ex
autonomous: true
must_haves:
  truths:
    - "GET /api/metrics returns JSON with queue_depth, task_latency (p50/p90/p99), agent_utilization, error_rates, and dets_health"
    - "MetricsCollector attaches to telemetry events and aggregates data in ETS with a 1-hour rolling window"
    - "Metrics snapshot is broadcast on PubSub 'metrics' topic every 10 seconds"
  artifacts:
    - path: "lib/agent_com/metrics_collector.ex"
      provides: "ETS-backed telemetry aggregation GenServer"
      contains: "defmodule AgentCom.MetricsCollector"
    - path: "lib/agent_com/endpoint.ex"
      provides: "GET /api/metrics endpoint"
      contains: "get \"/api/metrics\""
  key_links:
    - from: "lib/agent_com/metrics_collector.ex"
      to: ":telemetry"
      via: ":telemetry.attach_many/4 for task, agent, FSM, scheduler events"
      pattern: "telemetry.attach_many"
    - from: "lib/agent_com/endpoint.ex"
      to: "lib/agent_com/metrics_collector.ex"
      via: "AgentCom.MetricsCollector.snapshot/0 call"
      pattern: "MetricsCollector.snapshot"
    - from: "lib/agent_com/metrics_collector.ex"
      to: "Phoenix.PubSub"
      via: "Periodic broadcast on 'metrics' topic"
      pattern: "PubSub.broadcast.*metrics"
---

<objective>
Build the MetricsCollector GenServer that aggregates telemetry events into rolling-window metrics, expose them via GET /api/metrics, and add MetricsCollector to the supervision tree.

Purpose: Provides the data aggregation layer that the Alerter (plan 02), dashboard (plan 04), and API consumers need. Satisfies success criteria #1 (metrics endpoint).
Output: metrics_collector.ex, updated application.ex, updated endpoint.ex with /api/metrics.
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-metrics-alerting/14-RESEARCH.md
@lib/agent_com/telemetry.ex
@lib/agent_com/application.ex
@lib/agent_com/endpoint.ex
@lib/agent_com/dashboard_state.ex
@lib/agent_com/analytics.ex
@lib/agent_com/config.ex
@lib/agent_com/agent_fsm.ex
@lib/agent_com/task_queue.ex
@lib/agent_com/dets_backup.ex
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create MetricsCollector GenServer with ETS-backed telemetry aggregation</name>
  <files>lib/agent_com/metrics_collector.ex</files>
  <action>
Create `AgentCom.MetricsCollector` GenServer with these components:

**ETS Table:** `:agent_metrics` -- named, :set, :public, read_concurrency: true. Public because telemetry handlers run in emitting processes (not the MetricsCollector process).

**Telemetry Handler Registration** (in init):
Attach handlers via `:telemetry.attach_many/4` with SEPARATE handler IDs (not the same ID as the existing "agent-com-telemetry-logger" in Telemetry module). Use these handler groups:
- `"metrics-collector-tasks"`: task submit/assign/complete/fail/dead_letter/reclaim/retry
- `"metrics-collector-agents"`: agent connect/disconnect
- `"metrics-collector-fsm"`: fsm transition (single attach, not attach_many)
- `"metrics-collector-scheduler"`: scheduler attempt (single attach)

Wrap ALL telemetry handler callbacks in try/rescue (per existing pattern in AgentCom.Telemetry). Log handler crashes at :error level. This prevents `:telemetry` from silently detaching the handler on crash.

**Data Storage in ETS:**
- Counters: Use `:ets.update_counter/3` for atomic increments (tasks_submitted, tasks_completed, tasks_failed, tasks_dead_letter, tasks_reclaimed, tasks_retried). Store as `{:counter, key}` => count.
- Queue depth gauge: Store as `{:gauge, :queue_depth}` => value. Updated on scheduler:attempt event (measurements include queued_tasks).
- Duration data points: Use `GenServer.cast` to self for appending to bounded lists. Store as `{:durations, key}` => [{timestamp_ms, value_ms}, ...]. Cap at 10,000 entries per key. Keys: `:task_wait` (from task:assign wait_ms), `:task_duration` (from task:complete duration_ms).
- FSM transitions: Store as `{:transitions, agent_id}` => [{timestamp_ms, from_state, to_state}, ...]. Cap at 1,000 per agent.
- Agent online set: Store as `{:agents_online}` => MapSet of agent_ids. Updated on connect/disconnect.
- Queue depth trend: Store as `{:trend, :queue_depth}` => [depth1, depth2, ...]. Cap at 60 entries (10 min at 10s intervals).
- Cumulative counters: Separate from window counters. Stored as `{:cumulative, key}` => count. Never pruned.

**Periodic Tasks** (via Process.send_after in init and handle_info):
1. `:broadcast_snapshot` every 10 seconds -- calls `snapshot/0`, broadcasts `{:metrics_snapshot, snapshot}` on PubSub "metrics" topic.
2. `:cleanup_window` every 5 minutes -- prunes data points older than 1 hour from duration lists and transition lists. Also prunes entries beyond caps.
3. `:check_handlers` every 60 seconds -- verifies telemetry handlers are still attached via `:telemetry.list_handlers/1`. If detached, reattach. Log at :warning level.

**Public API:**
- `start_link/1` -- standard GenServer
- `snapshot/0` -- returns the full metrics map (computed from ETS, no GenServer call needed since ETS is :public). Cache the computed snapshot in ETS under `{:snapshot_cache}` key and refresh every 10s in the broadcast timer. The `/api/metrics` endpoint reads the cache for zero-cost reads.

**Snapshot Shape** (matches research spec):
```
%{
  timestamp: now_ms,
  window_ms: 3_600_000,
  queue_depth: %{current: N, trend: [...], max_1h: N, avg_1h: N.N},
  task_latency: %{
    window: %{p50: N, p90: N, p99: N, count: N, min: N, max: N, mean: N},
    cumulative: %{p50: N, p90: N, p99: N, count: N}
  },
  agent_utilization: %{
    system: %{total_agents: N, agents_online: N, agents_idle: N, agents_working: N, utilization_pct: N.N},
    per_agent: [%{agent_id: S, state: A, idle_pct_1h: N.N, working_pct_1h: N.N, blocked_pct_1h: N.N, tasks_completed_1h: N, avg_task_duration_ms: N}]
  },
  error_rates: %{
    window: %{total_tasks: N, failed: N, dead_letter: N, failure_rate_pct: N.N},
    cumulative: %{total_tasks: N, failed: N, dead_letter: N, failure_rate_pct: N.N}
  },
  dets_health: dets_health_map  # from DetsBackup.health_metrics/0, wrapped in try/rescue
}
```

**Percentile Calculation** (~5 lines, inline in module):
Sort duration list, index at floor(p * (count-1)) for p50/p90/p99. Return 0 for all if empty list.

**Agent Utilization** -- read FSM transitions from ETS within window, compute time in each state (idle/working/blocked) as percentage. For current agent states, call `AgentCom.AgentFSM.list_all/0` (wrap in try/rescue).

**Telemetry Event Handlers:**
- `handle_task_event/4`: On submit, increment counter + cumulative. On assign, record wait_ms duration. On complete, record duration_ms, increment completed counter + cumulative. On fail, increment failed counter + cumulative. On dead_letter, increment dead_letter counter + cumulative. On reclaim/retry, increment respective counters.
- `handle_agent_event/4`: On connect, add to agents_online set. On disconnect, remove from set.
- `handle_fsm_event/4`: Record transition {timestamp, from_state, to_state} for agent_id.
- `handle_scheduler_event/4`: Update queue_depth gauge from measurements.queued_tasks.

**Important:** The module MUST handle the case where ETS table doesn't exist yet (e.g., during testing or if called before init). Use try/rescue around ETS reads in snapshot/0.
  </action>
  <verify>
Run `mix compile` -- no warnings or errors. Module compiles cleanly.
Verify telemetry handler IDs don't conflict: grep for "metrics-collector" in the codebase to confirm unique IDs.
  </verify>
  <done>
MetricsCollector GenServer exists with ETS-backed aggregation, telemetry handler attachment, periodic snapshot broadcast, window cleanup, and handler health checks. snapshot/0 returns the full metrics map.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add supervision tree entry and GET /api/metrics endpoint</name>
  <files>lib/agent_com/application.ex, lib/agent_com/endpoint.ex</files>
  <action>
**application.ex changes:**
Add `{AgentCom.MetricsCollector, []}` to the children list AFTER `AgentCom.Scheduler` and BEFORE `AgentCom.DashboardState`. This ensures MetricsCollector can attach to telemetry events that Scheduler and TaskQueue emit, and is available before DashboardState starts consuming metrics.

**endpoint.ex changes:**
Add GET /api/metrics endpoint (no auth required -- same pattern as /api/dashboard/state which is for local network visibility). Place it near the dashboard state endpoint section.

```elixir
get "/api/metrics" do
  snapshot = AgentCom.MetricsCollector.snapshot()
  send_json(conn, 200, snapshot)
end
```

Update the @moduledoc route listing to include:
- `GET    /api/metrics          -- System metrics (queue depth, latency, utilization, errors)`

Also add to endpoint.ex @moduledoc:
- `GET    /api/alerts           -- Active alerts` (placeholder for plan 02)
  </action>
  <verify>
Run `mix compile` -- no errors.
Run `mix test` -- existing tests still pass (no regressions from supervision tree reordering).
  </verify>
  <done>
MetricsCollector is in the supervision tree after Scheduler and before DashboardState. GET /api/metrics endpoint returns the metrics snapshot JSON. Existing tests pass.
  </done>
</task>

</tasks>

<verification>
1. `mix compile` succeeds with no warnings
2. `mix test` passes (no regressions)
3. Start the application (`mix run --no-halt`), then `curl http://localhost:4000/api/metrics` returns JSON with queue_depth, task_latency, agent_utilization, error_rates, and dets_health keys
4. Check telemetry handlers are registered: in IEx, `:telemetry.list_handlers([:agent_com])` shows both "agent-com-telemetry-logger" and "metrics-collector-*" handlers
</verification>

<success_criteria>
- MetricsCollector GenServer starts in supervision tree and attaches to telemetry events
- GET /api/metrics returns the full metrics snapshot with all required fields
- Metrics data aggregates over a 1-hour rolling window with periodic cleanup
- Snapshots broadcast on PubSub "metrics" topic every 10 seconds
- All existing tests continue to pass
</success_criteria>

<output>
After completion, create `.planning/phases/14-metrics-alerting/14-01-SUMMARY.md`
</output>
