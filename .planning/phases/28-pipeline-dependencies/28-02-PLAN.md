---
phase: 28-pipeline-dependencies
plan: 02
type: tdd
wave: 2
depends_on: ["28-01"]
files_modified:
  - test/agent_com/task_queue_test.exs
  - test/agent_com/scheduler_test.exs
autonomous: true

must_haves:
  truths:
    - "Tests prove depends_on field persists through submit and retrieve"
    - "Tests prove scheduler skips tasks with incomplete dependencies"
    - "Tests prove scheduler schedules tasks with all dependencies completed"
    - "Tests prove independent tasks (no depends_on) are unaffected"
    - "Tests prove goal_progress returns correct counts"
    - "Tests prove submit rejects invalid dependency IDs"
    - "Tests prove backward compatibility with tasks lacking depends_on/goal_id"
  artifacts:
    - path: "test/agent_com/task_queue_test.exs"
      provides: "Tests for depends_on, goal_id, tasks_for_goal, goal_progress, dependency validation"
      contains: "depends_on"
    - path: "test/agent_com/scheduler_test.exs"
      provides: "Tests for dependency filtering in scheduling"
      contains: "depends_on"
  key_links:
    - from: "test/agent_com/task_queue_test.exs"
      to: "lib/agent_com/task_queue.ex"
      via: "Tests call TaskQueue.submit/1, tasks_for_goal/1, goal_progress/1"
      pattern: "TaskQueue\\."
    - from: "test/agent_com/scheduler_test.exs"
      to: "lib/agent_com/scheduler.ex"
      via: "Tests verify scheduling with dependency chains"
      pattern: "Scheduler"
---

<objective>
Write comprehensive tests for the Phase 28 pipeline dependency features: task dependency fields, scheduler filtering, goal progress tracking, and backward compatibility.

Purpose: Verify correctness of dependency ordering, goal tracking, and ensure zero regression on existing task pipeline behavior.
Output: Test suites covering all new behavior in task_queue_test.exs and scheduler_test.exs.
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-pipeline-dependencies/28-RESEARCH.md
@.planning/phases/28-pipeline-dependencies/28-01-SUMMARY.md
@lib/agent_com/task_queue.ex
@lib/agent_com/scheduler.ex
@test/agent_com/task_queue_test.exs
@test/agent_com/scheduler_test.exs
@test/support/test_factory.ex
</context>

<tasks>

<task type="auto">
  <name>Task 1: TDD tests for TaskQueue dependency and goal features</name>
  <files>test/agent_com/task_queue_test.exs</files>
  <action>
Add a new describe block "pipeline dependencies (Phase 28)" in task_queue_test.exs with these test cases:

**depends_on field persistence:**
- Submit task A (no deps), submit task B with `depends_on: [A.id]` -- verify B's depends_on contains A.id after get
- Submit task with `depends_on: []` -- verify stored as empty list
- Submit task with `goal_id: "goal-123"` -- verify goal_id is persisted and retrievable

**Dependency validation at submit:**
- Submit task with `depends_on: ["nonexistent-id"]` -- expect `{:error, {:invalid_dependencies, ["nonexistent-id"]}}`
- Submit task A, then submit task B with `depends_on: [A.id]` -- expect `{:ok, _}` (valid dep)
- Submit task with `depends_on: []` -- expect `{:ok, _}` (empty deps always valid)

**tasks_for_goal/1:**
- Submit 3 tasks with `goal_id: "goal-1"` and 2 tasks with `goal_id: "goal-2"` -- `tasks_for_goal("goal-1")` returns exactly 3 tasks
- `tasks_for_goal("nonexistent")` returns empty list

**goal_progress/1:**
- Submit 3 tasks for "goal-1", complete 1, dead-letter 1 -- `goal_progress("goal-1")` returns `%{total: 3, completed: 1, failed: 1, pending: 1}`

**list/1 with goal_id filter:**
- Submit tasks with different goal_ids -- `list(goal_id: "goal-1")` returns only tasks for that goal

**Backward compatibility:**
- Submit task without depends_on or goal_id params -- verify `Map.get(task, :depends_on, [])` returns `[]` and `Map.get(task, :goal_id, nil)` returns `nil`

Use existing test patterns: `setup` with DETS cleanup, `TestFactory.submit_task/1` for task creation. For completing/dead-lettering tasks, use `TaskQueue.complete_task/3` and the existing dead-letter mechanisms.

Each test should follow the standard pattern in the existing test file: setup agent state if needed, submit tasks, perform operations, assert outcomes.
  </action>
  <verify>Run `mix test test/agent_com/task_queue_test.exs` -- all tests pass including new ones. Run `mix test test/agent_com/task_queue_test.exs --trace` to see test names.</verify>
  <done>At least 8 new tests covering depends_on persistence, dependency validation, tasks_for_goal, goal_progress, list filtering, and backward compatibility -- all passing.</done>
</task>

<task type="auto">
  <name>Task 2: TDD tests for Scheduler dependency filtering</name>
  <files>test/agent_com/scheduler_test.exs</files>
  <action>
Add a new describe block "dependency filtering (Phase 28)" in scheduler_test.exs with these test cases:

**3-task dependency chain (A -> B -> C):**
- Submit task A (no deps), B depends on A, C depends on B
- Create an idle agent
- Trigger scheduling -- only A should be assigned (B and C blocked)
- Complete A, trigger scheduling -- B should now be assigned
- Complete B, trigger scheduling -- C should now be assigned

**Independent tasks unaffected:**
- Submit task X (no depends_on), task Y (no depends_on)
- Both should be schedulable immediately (regression test)

**Mixed independent and dependent:**
- Submit task A (no deps), task B depends on A, task C (no deps)
- Trigger scheduling -- A and C should be schedulable, B should be blocked

**Dead-lettered dependency blocks dependent:**
- Submit task A, submit B depends on A
- Dead-letter A (fail it past max retries)
- Trigger scheduling -- B should NOT be scheduled (A is dead_letter, not completed)

Use existing test patterns from scheduler_test.exs: create agents via TestFactory.create_agent/1, submit tasks, trigger scheduling via PubSub event or direct call, and assert task states.

Follow the existing test setup patterns for scheduler tests -- typically starting TaskQueue, AgentManager, Scheduler, and LlmRegistry in the test setup block.
  </action>
  <verify>Run `mix test test/agent_com/scheduler_test.exs` -- all tests pass including new ones. Run `mix test` -- full suite green.</verify>
  <done>At least 4 new scheduler tests covering dependency chain ordering, independent task non-regression, mixed scheduling, and dead-letter blocking -- all passing. Full test suite green.</done>
</task>

</tasks>

<verification>
1. `mix test test/agent_com/task_queue_test.exs` -- all tests pass (existing + new)
2. `mix test test/agent_com/scheduler_test.exs` -- all tests pass (existing + new)
3. `mix test` -- full suite green, zero regressions
4. Test count increased by at least 12 tests
</verification>

<success_criteria>
- All new tests pass on first run (implementation from 28-01 is correct)
- At least 12 new test cases covering dependency fields, validation, filtering, goal tracking
- Zero regressions on existing test suite
- Tests cover edge cases: empty deps, invalid deps, dead-letter deps, backward compat
</success_criteria>

<output>
After completion, create `.planning/phases/28-pipeline-dependencies/28-02-SUMMARY.md`
</output>
