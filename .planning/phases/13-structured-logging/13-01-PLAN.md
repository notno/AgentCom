---
phase: 13-structured-logging
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mix.exs
  - config/config.exs
  - config/dev.exs
  - config/prod.exs
  - lib/agent_com/telemetry.ex
  - lib/agent_com/application.ex
autonomous: true

must_haves:
  truths:
    - "LoggerJSON dependency is installed and compiles"
    - "Logger output from any module is formatted as valid JSON on stdout"
    - "Every JSON log entry includes function name and line number metadata (per locked decision on full trace metadata)"
    - "A rotating log file is written to priv/logs/agent_com.log"
    - "Auth tokens appearing in log metadata are redacted"
    - "AgentCom.Telemetry module defines the complete event catalog and attaches handlers on application start"
  artifacts:
    - path: "lib/agent_com/telemetry.ex"
      provides: "Telemetry event catalog, handler attachment, logging handler"
      exports: ["attach_handlers/0", "handle_event/4"]
    - path: "mix.exs"
      provides: "LoggerJSON dependency declaration"
      contains: "logger_json"
    - path: "config/config.exs"
      provides: "LoggerJSON formatter config for stdout + file handler with compile-time metadata"
      contains: "LoggerJSON.Formatters.Basic"
  key_links:
    - from: "lib/agent_com/application.ex"
      to: "lib/agent_com/telemetry.ex"
      via: "AgentCom.Telemetry.attach_handlers() called in start/2"
      pattern: "Telemetry\\.attach_handlers"
    - from: "config/config.exs"
      to: "LoggerJSON"
      via: "formatter config for :default_handler"
      pattern: "LoggerJSON\\.Formatters\\.Basic"
---

<objective>
Set up the structured logging and telemetry infrastructure that all subsequent plans depend on.

Purpose: Install LoggerJSON, configure dual-output JSON logging (stdout + rotating files) with secret redaction, create the AgentCom.Telemetry module with the complete event catalog and logging handler, and wire telemetry handler attachment into Application.start/2. After this plan, any Logger call from any module will output valid JSON with full trace metadata (including function name and line number), and the telemetry event system is ready for emitters.

Output: Working LoggerJSON config, AgentCom.Telemetry module, file rotation handler, updated Application.start
</objective>

<execution_context>
@C:/Users/nrosq/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nrosq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-structured-logging/13-RESEARCH.md
@.planning/phases/13-structured-logging/13-CONTEXT.md
@config/config.exs
@config/dev.exs
@config/prod.exs
@config/test.exs
@mix.exs
@lib/agent_com/application.ex
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add LoggerJSON dependency and configure dual-output JSON logging with full trace metadata</name>
  <files>
    mix.exs
    config/config.exs
    config/dev.exs
    config/prod.exs
  </files>
  <action>
    1. In mix.exs, add `{:logger_json, "~> 7.0"}` to the deps list.

    2. Run `mix deps.get` to install LoggerJSON.

    3. Replace the existing Logger config in config/config.exs. The current config uses the OLD backend format:
       ```
       config :logger, :console,
         format: "$time $metadata[$level] $message\n",
         metadata: [:request_id, :agent_id]
       ```
       Replace with the NEW OTP handler format:
       ```elixir
       # Structured JSON logging via LoggerJSON (Phase 13)
       #
       # Compile-time metadata: capture :mfa (module/function/arity) and :line
       # in every log entry. Per locked decision: "Full trace metadata in every
       # log entry: timestamp, level, module, message, pid, node, function name,
       # line number". LoggerJSON.Formatters.Basic automatically includes these
       # when they are present in the Logger metadata.
       config :logger, :default_handler,
         formatter: LoggerJSON.Formatters.Basic.new(
           metadata: {:all_except, [:conn, :crash_reason]},
           redactors: [{LoggerJSON.Redactors.RedactKeys, keys: ["token", "auth_token", "secret"]}]
         )

       # Enable compile-time metadata injection for function name and line number.
       # This causes Logger to automatically attach :mfa and :line to every log
       # call at compile time, so the JSON output includes "mfa" and "line" fields.
       config :logger, :default_handler, %{
         metadata: %{
           mfa: true,
           line: true
         }
       }
       ```

       IMPORTANT: The Elixir Logger compile-time metadata for :mfa and :line is
       controlled by the Logger itself, not by LoggerJSON. In Elixir's Logger,
       :mfa and :line are ALWAYS captured at compile time and passed as metadata
       to handlers/formatters. LoggerJSON.Formatters.Basic includes them in JSON
       output when metadata is set to {:all_except, [...]} (which does NOT exclude
       them). Verify after implementation that the JSON output contains "mfa" (as
       a string like "Elixir.MyModule.my_func/1") and "line" (as an integer).

       If the JSON output does NOT include mfa/line fields, the fallback approach
       is to explicitly add them to Logger metadata in config:
       ```elixir
       # Fallback: if mfa/line not appearing, ensure they're in default metadata
       config :logger, compile_time_purge_matching: []
       ```
       The key insight: LoggerJSON.Formatters.Basic with `metadata: {:all_except, [...]}`
       will serialize ALL metadata keys present. Elixir Logger always injects :mfa
       and :line at compile time. So as long as we don't exclude them, they appear.

       File handler: rotating log files for historical analysis
       ```elixir
       config :logger, [
         {:handler, :file_handler, :logger_std_h, %{
           config: %{
             file: ~c"priv/logs/agent_com.log",
             max_no_bytes: 10_000_000,
             max_no_files: 5,
             compress_on_rotate: true
           },
           formatter: LoggerJSON.Formatters.Basic.new(
             metadata: {:all_except, [:conn, :crash_reason]},
             redactors: [{LoggerJSON.Redactors.RedactKeys, keys: ["token", "auth_token", "secret"]}]
           )
         }}
       ]
       ```

    4. Ensure the `priv/logs/` directory exists (create if not). Add `priv/logs/*.log*` to .gitignore if not already there.

    5. In config/test.exs, keep the existing `config :logger, level: :warning` but override the file handler to prevent test log files. Add:
       ```elixir
       # Disable file handler in test to avoid log file noise
       config :logger, [{:handler, :file_handler, :logger_std_h, %{config: %{type: :standard_io}}}]
       ```
       Actually, simpler approach: just remove the file handler in test by not adding it. The config/config.exs sets it, but test.exs can override the handler list. Check LoggerJSON docs for test-appropriate config. If overriding is complex, just set test log level to :warning (already done) which suppresses most output anyway.

    6. In config/dev.exs, optionally add a comment noting JSON output is active. Keep JSON format in dev for consistency (per research recommendation).

    7. In config/prod.exs, keep same JSON config (inherited from config.exs). No changes needed unless prod needs different log level. Add `config :logger, level: :info` to set production default.

    8. VERIFY function/line metadata: After config is in place, run a test Logger call and confirm the JSON output includes "mfa" and "line" fields. This is the locked decision requirement. If they do not appear, investigate LoggerJSON.Formatters.Basic source to understand how metadata keys are serialized and adjust config accordingly.

    IMPORTANT: The existing config.exs uses `config :logger, :console, ...` which is the OLD Elixir <= 1.14 backend format. This MUST be replaced entirely with the new `:default_handler` format. Do NOT keep both -- they conflict.
  </action>
  <verify>
    Run `mix deps.get && mix compile` -- must succeed with zero errors.
    Run `mix run -e "require Logger; Logger.info(\"test\"); Logger.info(\"token_test\", token: \"secret123\")"` and verify:
    1. Output is valid JSON (one JSON object per line)
    2. The "token" field in the second log entry shows "[REDACTED]" not "secret123"
    3. Check that priv/logs/agent_com.log exists and contains JSON output
    4. CRITICAL: Verify that JSON output contains "mfa" field (e.g., value like "Elixir.AgentCom.SomeModule.some_func/1" or similar) and "line" field (integer). Parse a log line with `mix run -e "require Logger; Logger.info(\"meta_test\")"` and pipe through `jq .` or manually inspect. Both fields MUST be present per locked decision.
  </verify>
  <done>
    LoggerJSON 7.x installed. All Logger output is JSON-formatted on stdout. Every log entry includes full trace metadata: timestamp, level, module, message, pid, node, function name (mfa), and line number. Rotating file handler writes to priv/logs/agent_com.log (10MB, 5 files). Auth tokens are redacted in log output. mix compile succeeds.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create AgentCom.Telemetry module and wire into Application.start</name>
  <files>
    lib/agent_com/telemetry.ex
    lib/agent_com/application.ex
  </files>
  <action>
    1. Create lib/agent_com/telemetry.ex with:
       - @moduledoc documenting the complete event catalog (see RESEARCH.md "Complete Telemetry Event Catalog" section for full list)
       - Standard metadata keys documentation: module, agent_id, task_id, request_id, table (for DETS ops)
       - attach_handlers/0 function that uses :telemetry.attach_many/4 to attach a logging handler for ALL events in the catalog:
         - Task lifecycle: [:agent_com, :task, :submit], [:agent_com, :task, :assign], [:agent_com, :task, :complete], [:agent_com, :task, :fail], [:agent_com, :task, :dead_letter], [:agent_com, :task, :reclaim], [:agent_com, :task, :retry]
         - Agent lifecycle: [:agent_com, :agent, :connect], [:agent_com, :agent, :disconnect], [:agent_com, :agent, :evict]
         - FSM: [:agent_com, :fsm, :transition]
         - Scheduler: [:agent_com, :scheduler, :attempt], [:agent_com, :scheduler, :match]
         - DETS spans (start/stop/exception for each): [:agent_com, :dets, :backup, :*], [:agent_com, :dets, :compaction, :*], [:agent_com, :dets, :restore, :*]
       - handle_event/4 callback that logs the telemetry event at :info level using structured metadata. Wrap in try/rescue to prevent handler detachment on crash (per research Pitfall 3). Log handler crashes at :error level.
       - Use `&__MODULE__.handle_event/4` (module function capture, not anonymous function) for performance per research best practice.

    2. In lib/agent_com/application.ex, add `AgentCom.Telemetry.attach_handlers()` as the FIRST line inside start/2, BEFORE the children list and BEFORE the ETS table creation. Telemetry handlers should be attached before any child process starts emitting events.

    Discretion decisions applied:
    - Flat correlation IDs (request_id) per research recommendation -- no span-style parent/child
    - Logger.metadata per-process per research recommendation -- no shared AgentCom.Log helper module
    - Telemetry events do NOT feed dashboard -- defer to Phase 14 per research recommendation
  </action>
  <verify>
    Run `mix compile` -- must succeed.
    Run `mix run -e ":telemetry.execute([:agent_com, :task, :submit], %{queue_depth: 5}, %{task_id: \"test-123\", priority: \"normal\", submitted_by: \"test-agent\"})"` and verify a JSON log entry is emitted containing the telemetry event data.
    Run `mix run -e "IO.inspect(:telemetry.list_handlers([:agent_com, :task, :submit]))"` -- should show at least one handler attached.
  </verify>
  <done>
    AgentCom.Telemetry module exists with complete event catalog documentation and working handler attachment. Telemetry handlers are attached on application start. Emitting a test telemetry event produces a structured JSON log entry. Handler crash safety is implemented via try/rescue.
  </done>
</task>

</tasks>

<verification>
- `mix deps.get && mix compile` succeeds
- `mix test` passes (existing tests still work with new JSON logging)
- Logger output is valid JSON on stdout
- JSON log entries include mfa (function name) and line (line number) metadata fields
- priv/logs/agent_com.log receives JSON log output
- Telemetry handlers are attached (verified via :telemetry.list_handlers)
- Token redaction works in log output
</verification>

<success_criteria>
1. LoggerJSON 7.x is installed and configured as the default formatter
2. Dual output active: stdout JSON + rotating file at priv/logs/agent_com.log
3. Every log entry includes full trace metadata: timestamp, level, module, message, pid, node, function name (mfa), line number
4. Secret redaction configured for token, auth_token, secret keys
5. AgentCom.Telemetry module defines complete event catalog and attaches logging handlers
6. Application.start calls Telemetry.attach_handlers before starting children
7. All existing tests pass with new logging config
</success_criteria>

<output>
After completion, create `.planning/phases/13-structured-logging/13-01-SUMMARY.md`
</output>
